{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9019ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Import Libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60ece41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Set Device and Parameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMG_SIZE = 64\n",
    "SEQ_LEN = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_CLASSES = 5\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHS = 10\n",
    "DATA_DIR = \"eye_gaze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ec99785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Custom Dataset for Sequence Loading\n",
    "class GazeSequenceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, seq_len=10):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.seq_len = seq_len\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "\n",
    "        for cls in self.classes:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            files = sorted([os.path.join(cls_dir, f) for f in os.listdir(cls_dir) if f.endswith('.jpg')])\n",
    "            # Create sequences from the sorted images\n",
    "            for i in range(len(files) - seq_len + 1):\n",
    "                seq = files[i:i+seq_len]\n",
    "                self.samples.append((seq, self.class_to_idx[cls]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_paths, label = self.samples[idx]\n",
    "        seq = []\n",
    "        for img_path in seq_paths:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            seq.append(img)\n",
    "        seq = torch.stack(seq)  # shape: (seq_len, C, H, W)\n",
    "        return seq, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12821d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sequences: 5955\n",
      "Test Sequences: 1455\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Define Transforms and Load Datasets\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = GazeSequenceDataset(os.path.join(DATA_DIR, 'train'), transform=transform, seq_len=SEQ_LEN)\n",
    "test_dataset = GazeSequenceDataset(os.path.join(DATA_DIR, 'test'), transform=transform, seq_len=SEQ_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train Sequences: {len(train_dataset)}\")\n",
    "print(f\"Test Sequences: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daca223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Define the MobileNetV2 + LSTM Model\n",
    "class MobileNetLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=5, lstm_layers=1):\n",
    "        super(MobileNetLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Freeze all except last two layers (17 and 18)\n",
    "        for name, param in self.feature_extractor.named_parameters():\n",
    "            if \"17\" not in name and \"18\" not in name:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)  # (B*T, C, H, W)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.feature_extractor(x)\n",
    "            features = self.pool(features).view(features.size(0), -1)\n",
    "\n",
    "        features = features.view(b, t, -1)         # (B, T, 1280)\n",
    "        lstm_out, _ = self.lstm(features)          # (B, T, hidden_dim)\n",
    "        final_output = lstm_out[:, -1, :]          # Last time-step\n",
    "        return self.classifier(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1181c1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nelly\\Desktop\\Bea_Tap\\bea_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nelly\\Desktop\\Bea_Tap\\bea_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6348, Accuracy: 89.84%\n",
      "Epoch [2/10], Loss: 0.4713, Accuracy: 98.25%\n",
      "Epoch [3/10], Loss: 0.4532, Accuracy: 98.72%\n",
      "Epoch [4/10], Loss: 0.4407, Accuracy: 99.06%\n",
      "Epoch [5/10], Loss: 0.4384, Accuracy: 99.28%\n",
      "Epoch [6/10], Loss: 0.4198, Accuracy: 99.61%\n",
      "Epoch [7/10], Loss: 0.4151, Accuracy: 99.71%\n",
      "Epoch [8/10], Loss: 0.4125, Accuracy: 99.76%\n",
      "Epoch [9/10], Loss: 0.4112, Accuracy: 99.75%\n",
      "Epoch [10/10], Loss: 0.4111, Accuracy: 99.73%\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Train the Model\n",
    "model = MobileNetLSTM(hidden_dim=HIDDEN_DIM, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# âœ… Unfreeze final layers for fine-tuning\n",
    "for name, param in model.feature_extractor.named_parameters():\n",
    "    if \"18\" in name or \"17\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# âœ… Apply label smoothing and scheduler\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for sequences, labels in train_loader:\n",
    "        sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate batch accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfe4025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'eye_gaze_lstm_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Save the Trained Model\n",
    "torch.save(model.state_dict(), \"eye_gaze_lstm_model.pth\")\n",
    "print(\"Model saved as 'eye_gaze_lstm_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec325f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd23c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57581d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       1.00      1.00      1.00       291\n",
      "        left       1.00      1.00      1.00       291\n",
      "       right       1.00      1.00      1.00       291\n",
      "    straight       1.00      1.00      1.00       291\n",
      "          up       1.00      1.00      1.00       291\n",
      "\n",
      "    accuracy                           1.00      1455\n",
      "   macro avg       1.00      1.00      1.00      1455\n",
      "weighted avg       1.00      1.00      1.00      1455\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 8: Evaluate After Training\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, labels in test_loader:\n",
    "        sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(sequences)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=test_dataset.classes))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "            xticklabels=test_dataset.classes,\n",
    "            yticklabels=test_dataset.classes)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9afdb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNetLSTM Model Definition\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class MobileNetLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=5, lstm_layers=1):\n",
    "        super(MobileNetLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        return self.classifier(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40289426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class MobileNetLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=5, lstm_layers=1):\n",
    "        super(MobileNetLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        return self.classifier(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c73bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”µ Press 'q' to quit\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: Real-Time Webcam Eye Gaze Shift Counter (Debounced, Accurate)\n",
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from collections import deque\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# === Define MobileNetLSTM ===\n",
    "class MobileNetLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=5, lstm_layers=1):\n",
    "        super(MobileNetLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim,\n",
    "                            num_layers=lstm_layers, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        return self.classifier(out)\n",
    "\n",
    "# === Constants ===\n",
    "HIDDEN_DIM = 128\n",
    "NUM_CLASSES = 5\n",
    "SEQ_LEN = 10\n",
    "IMG_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load Model ===\n",
    "model = MobileNetLSTM(hidden_dim=HIDDEN_DIM, num_classes=NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"eye_gaze_lstm_model.pth\", map_location=DEVICE))\n",
    "model.eval()\n",
    "\n",
    "# === Transform ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# === MediaPipe Setup ===\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1,\n",
    "                                   refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "LEFT_EYE_IDS = [33, 133, 159, 145]\n",
    "RIGHT_EYE_IDS = [362, 263, 386, 374]\n",
    "\n",
    "# === Buffers ===\n",
    "frame_buffer = deque(maxlen=SEQ_LEN)\n",
    "recent_preds = deque(maxlen=3)\n",
    "prev_confirmed_label = None\n",
    "gaze_shift_count = 0\n",
    "last_valid_time = time.time()\n",
    "debounce_interval = 0.75  # seconds\n",
    "\n",
    "# === Webcam ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"ðŸ”µ Press 'q' to quit\")\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        eye_x = [int(landmarks[i].x * w) for i in LEFT_EYE_IDS + RIGHT_EYE_IDS]\n",
    "        eye_y = [int(landmarks[i].y * h) for i in LEFT_EYE_IDS + RIGHT_EYE_IDS]\n",
    "\n",
    "        x_min = max(min(eye_x) - 20, 0)\n",
    "        x_max = min(max(eye_x) + 20, w)\n",
    "        y_min = max(min(eye_y) - 20, 0)\n",
    "        y_max = min(max(eye_y) + 20, h)\n",
    "\n",
    "        eye_crop = rgb[y_min:y_max, x_min:x_max]\n",
    "        if eye_crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        for idx in LEFT_EYE_IDS + RIGHT_EYE_IDS:\n",
    "            cx, cy = int(landmarks[idx].x * w), int(landmarks[idx].y * h)\n",
    "            cv2.circle(frame, (cx, cy), 2, (0, 255, 0), -1)\n",
    "\n",
    "        img_tensor = transform(cv2.resize(eye_crop, (IMG_SIZE, IMG_SIZE)))\n",
    "        frame_buffer.append(img_tensor)\n",
    "\n",
    "        if len(frame_buffer) == SEQ_LEN:\n",
    "            with torch.no_grad():\n",
    "                seq_input = torch.stack(list(frame_buffer)).unsqueeze(0).to(DEVICE)\n",
    "                output = model(seq_input)\n",
    "                _, pred = torch.max(output, 1)\n",
    "                label = pred.item()\n",
    "                recent_preds.append(label)\n",
    "\n",
    "            # Confirmed label only if 3 most recent are identical\n",
    "            if recent_preds.count(label) == len(recent_preds):\n",
    "                now = time.time()\n",
    "                if label != prev_confirmed_label and now - last_valid_time > debounce_interval:\n",
    "                    gaze_shift_count += 1\n",
    "                    prev_confirmed_label = label\n",
    "                    last_valid_time = now\n",
    "\n",
    "    cv2.putText(frame, f\"Gaze Shifts: {gaze_shift_count}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Eye Gaze Shift Counter\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6115d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nelly\\Desktop\\Bea_Tap\\bea_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nelly\\Desktop\\Bea_Tap\\bea_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tkinter import Tk, Button, Label, filedialog\n",
    "from torchvision import transforms\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "\n",
    "# === Define Model ===\n",
    "class MobileNetLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128, num_classes=5):\n",
    "        super(MobileNetLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim,\n",
    "                            batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        return self.classifier(out)\n",
    "\n",
    "# === Load Model ===\n",
    "model = MobileNetLSTM(hidden_dim=128, num_classes=5)\n",
    "model.load_state_dict(torch.load(\"eye_gaze_lstm_model.pth\", map_location=\"cpu\"))\n",
    "model.eval()\n",
    "\n",
    "# === Preprocessing ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# === MediaPipe Setup ===\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "LEFT_EYE_IDS = [33, 133, 159, 145]\n",
    "RIGHT_EYE_IDS = [362, 263, 386, 374]\n",
    "\n",
    "def count_gaze_shifts(video_path):\n",
    "    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1,\n",
    "                                      refine_landmarks=True, min_detection_confidence=0.5,\n",
    "                                      min_tracking_confidence=0.5)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_buffer = deque(maxlen=10)\n",
    "    recent_preds = deque(maxlen=3)\n",
    "    prev_label = None\n",
    "    gaze_shifts = 0\n",
    "    debounce_time = time.time()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        h, w, _ = frame.shape\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0].landmark\n",
    "            eye_x = [int(landmarks[i].x * w) for i in LEFT_EYE_IDS + RIGHT_EYE_IDS]\n",
    "            eye_y = [int(landmarks[i].y * h) for i in LEFT_EYE_IDS + RIGHT_EYE_IDS]\n",
    "\n",
    "            x_min = max(min(eye_x) - 20, 0)\n",
    "            x_max = min(max(eye_x) + 20, w)\n",
    "            y_min = max(min(eye_y) - 20, 0)\n",
    "            y_max = min(max(eye_y) + 20, h)\n",
    "\n",
    "            eye_crop = rgb[y_min:y_max, x_min:x_max]\n",
    "            if eye_crop.size == 0:\n",
    "                continue\n",
    "\n",
    "            img_tensor = transform(cv2.resize(eye_crop, (64, 64)))\n",
    "            frame_buffer.append(img_tensor)\n",
    "\n",
    "            if len(frame_buffer) == 10:\n",
    "                with torch.no_grad():\n",
    "                    input_seq = torch.stack(list(frame_buffer)).unsqueeze(0)\n",
    "                    out = model(input_seq)\n",
    "                    _, pred = torch.max(out, 1)\n",
    "                    label = pred.item()\n",
    "                    recent_preds.append(label)\n",
    "\n",
    "                # Count shift only if new consistent label appears\n",
    "                if recent_preds.count(label) == len(recent_preds):\n",
    "                    now = time.time()\n",
    "                    if label != prev_label and now - debounce_time > 0.75:\n",
    "                        gaze_shifts += 1\n",
    "                        prev_label = label\n",
    "                        debounce_time = now\n",
    "\n",
    "    cap.release()\n",
    "    face_mesh.close()\n",
    "    return gaze_shifts\n",
    "\n",
    "# === GUI Function ===\n",
    "def browse_and_analyze():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4;*.avi;*.mov\")])\n",
    "    if file_path:\n",
    "        result_label.config(text=\"Analyzing video, please wait...\")\n",
    "        root.update()\n",
    "        shifts = count_gaze_shifts(file_path)\n",
    "        result_label.config(text=f\"ðŸŽ¯ Eye Gaze Shift Count: {shifts}\")\n",
    "\n",
    "# === Tkinter GUI ===\n",
    "root = Tk()\n",
    "root.title(\"Eye Gaze Shift Counter\")\n",
    "root.geometry(\"400x200\")\n",
    "\n",
    "button = Button(root, text=\"Upload Video File\", command=browse_and_analyze, font=(\"Arial\", 12))\n",
    "button.pack(pady=30)\n",
    "\n",
    "result_label = Label(root, text=\"\", font=(\"Arial\", 14))\n",
    "result_label.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bea_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
