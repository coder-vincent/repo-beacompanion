{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55c8154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (2.7.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torchvision in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\nelly\\Desktop\\BEA_Project_2\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision opencv-python matplotlib seaborn tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee680558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ef072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder, label, transform=None, seq_len=10):\n",
    "        self.transform = transform\n",
    "        self.seq_len = seq_len\n",
    "        self.label = label\n",
    "        self.samples = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".mp4\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def read_video(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (64, 64))\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) < self.seq_len:\n",
    "            return None\n",
    "        idxs = np.linspace(0, len(frames) - 1, self.seq_len).astype(int)\n",
    "        return torch.stack([frames[i] for i in idxs])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        frames = self.read_video(path)\n",
    "        while frames is None:\n",
    "            idx = (idx + 1) % len(self.samples)\n",
    "            path = self.samples[idx]\n",
    "            frames = self.read_video(path)\n",
    "        return frames, torch.tensor(self.label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27bdaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 260 | Test: 64\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "base = \"tapping_hands\"\n",
    "\n",
    "train_data = [\n",
    "    VideoDataset(os.path.join(base, \"tapping/training\"), 1, transform),\n",
    "    VideoDataset(os.path.join(base, \"non-tapping/training\"), 0, transform)\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    VideoDataset(os.path.join(base, \"tapping/testing\"), 1, transform),\n",
    "    VideoDataset(os.path.join(base, \"non-tapping/testing\"), 0, transform)\n",
    "]\n",
    "\n",
    "train_dataset = ConcatDataset(train_data)\n",
    "test_dataset = ConcatDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0dac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6426344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:08<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 32.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:17<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Loss: 17.2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:23<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Loss: 13.2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:10<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Loss: 11.9543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Loss: 7.8394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Loss: 5.3920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Loss: 7.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Loss: 9.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:05<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Loss: 9.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:20<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Loss: 7.0499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:18<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Loss: 5.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:12<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Loss: 6.3813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:04<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Loss: 3.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:06<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Loss: 5.5173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:15<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Loss: 5.1224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:08<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Loss: 6.7755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:09<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Loss: 8.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:10<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Loss: 3.4721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:05<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Loss: 2.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65/65 [01:05<00:00,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Loss: 5.2937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNLSTM().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22db8af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Tapping       1.00      1.00      1.00        32\n",
      "     Tapping       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"\\nAccuracy: {acc:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Non-Tapping\", \"Tapping\"]))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Tapping\", \"Tapping\"], yticklabels=[\"Non-Tapping\", \"Tapping\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66797f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as bea_cnn_lstm_v2.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"bea_cnn_lstm_v2.pth\")\n",
    "print(\"Model saved as bea_cnn_lstm_v2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3440cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: jax in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (3.10.3)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from mediapipe) (2.3.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from jax->mediapipe) (1.15.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.58.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nelly\\desktop\\bea_project_2\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\nelly\\Desktop\\BEA_Project_2\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409ca543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nelly\\Desktop\\BEA_Project_2\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nelly\\Desktop\\BEA_Project_2\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- Model Definition ---\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "# --- Setup ---\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "AUDIO_FILE = \"beep.wav\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"bea_cnn_lstm_v2.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Init audio\n",
    "pygame.mixer.init()\n",
    "if os.path.exists(AUDIO_FILE):\n",
    "    beep = pygame.mixer.Sound(AUDIO_FILE)\n",
    "else:\n",
    "    beep = None\n",
    "\n",
    "# Init mediapipe\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hand_tracker = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Frame transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- GUI App ---\n",
    "class TapCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"BEA - Tapping Counter (Per Minute Display)\")\n",
    "\n",
    "        self.canvas = tk.Label(root)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.count_label = tk.Label(root, text=\"Taps this minute: 0\", font=(\"Arial\", 18))\n",
    "        self.count_label.pack(pady=5)\n",
    "\n",
    "        self.total_label = tk.Label(root, text=\"Total Minutes Logged: 0\", font=(\"Arial\", 14))\n",
    "        self.total_label.pack(pady=5)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.prev_gray = None\n",
    "        self.frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "        self.tap_count = 0\n",
    "        self.total_minutes = 0\n",
    "        self.prev_pred = 0\n",
    "        self.last_tap_time = time.time()\n",
    "        self.min_interval = 0.1\n",
    "\n",
    "        self.start_time = time.time()\n",
    "        self.last_logged_minute = 0\n",
    "\n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(10, self.update_frame)\n",
    "            return\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        display_img = cv2.resize(rgb, (640, 480))\n",
    "        model_input_frame = display_img.copy()\n",
    "\n",
    "        # Draw hand skeletons\n",
    "        results = hand_tracker.process(display_img)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(display_img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        img = Image.fromarray(display_img)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.canvas.imgtk = imgtk\n",
    "        self.canvas.configure(image=imgtk)\n",
    "\n",
    "        gray = cv2.cvtColor(model_input_frame, cv2.COLOR_RGB2GRAY)\n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "            self.root.after(30, self.update_frame)\n",
    "            return\n",
    "\n",
    "        curr_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "        diff = cv2.absdiff(self.prev_gray, curr_gray)\n",
    "        self.prev_gray = curr_gray\n",
    "\n",
    "        diff = np.expand_dims(diff, axis=-1)\n",
    "        diff = np.repeat(diff, 3, axis=-1)\n",
    "        diff = transform(diff)\n",
    "        self.frame_queue.append(diff)\n",
    "\n",
    "        if len(self.frame_queue) == SEQ_FRAMES:\n",
    "            sequence = torch.stack(list(self.frame_queue)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(sequence)\n",
    "                probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                pred = np.argmax(probs)\n",
    "\n",
    "            current_time = time.time()\n",
    "            if (\n",
    "                self.prev_pred == 0 and pred == 1 and\n",
    "                (current_time - self.last_tap_time > self.min_interval)\n",
    "            ):\n",
    "                self.tap_count += 1\n",
    "                self.last_tap_time = current_time\n",
    "                self.count_label.config(text=f\"Taps this minute: {self.tap_count}\")\n",
    "                if beep: beep.play()\n",
    "\n",
    "            self.prev_pred = pred\n",
    "\n",
    "        elapsed_minutes = int((time.time() - self.start_time) // 60)\n",
    "        if elapsed_minutes > self.last_logged_minute:\n",
    "            self.last_logged_minute = elapsed_minutes\n",
    "            self.total_minutes += 1\n",
    "            self.count_label.config(text=f\"Taps this minute: 0\")\n",
    "            self.total_label.config(text=f\"Total Minutes Logged: {self.total_minutes}\")\n",
    "            self.tap_count = 0\n",
    "\n",
    "        self.root.after(30, self.update_frame)\n",
    "\n",
    "    def on_close(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "# --- Run GUI ---\n",
    "root = tk.Tk()\n",
    "app = TapCounterApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", app.on_close)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e514857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nelly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\nelly\\AppData\\Local\\Temp\\ipykernel_30856\\1879935836.py\", line 130, in process_video\n",
      "    imgtk = ImageTk.PhotoImage(image=img)\n",
      "  File \"c:\\Users\\nelly\\Desktop\\BEA_Project_2\\.venv\\lib\\site-packages\\PIL\\ImageTk.py\", line 129, in __init__\n",
      "    self.__photo = tkinter.PhotoImage(**kw)\n",
      "  File \"C:\\Users\\nelly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 4093, in __init__\n",
      "    Image.__init__(self, 'photo', name, cnf, master, **kw)\n",
      "  File \"C:\\Users\\nelly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 4026, in __init__\n",
      "    master = _get_default_root('create image')\n",
      "  File \"C:\\Users\\nelly\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 297, in _get_default_root\n",
      "    raise RuntimeError(f\"Too early to {what}: no default root window\")\n",
      "RuntimeError: Too early to create image: no default root window\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import time\n",
    "import pygame\n",
    "import os\n",
    "\n",
    "# --- Model Definition ---\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "# --- Setup ---\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "AUDIO_FILE = \"beep.wav\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"bea_cnn_lstm_v2.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Init audio\n",
    "pygame.mixer.init()\n",
    "if os.path.exists(AUDIO_FILE):\n",
    "    beep = pygame.mixer.Sound(AUDIO_FILE)\n",
    "else:\n",
    "    beep = None\n",
    "\n",
    "# Frame transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- GUI App ---\n",
    "class TapVideoApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"BEA - Tapping Counter (Video Upload)\")\n",
    "\n",
    "        self.canvas = tk.Label(root)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.count_label = tk.Label(root, text=\"Taps Detected: 0\", font=(\"Arial\", 18))\n",
    "        self.count_label.pack(pady=10)\n",
    "\n",
    "        self.upload_btn = tk.Button(root, text=\"Upload Video\", command=self.process_video)\n",
    "        self.upload_btn.pack(pady=10)\n",
    "\n",
    "        self.frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "        self.tap_count = 0\n",
    "        self.prev_pred = 0\n",
    "        self.min_interval = 0.1\n",
    "        self.last_tap_time = time.time()\n",
    "\n",
    "    def process_video(self):\n",
    "        video_path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4 *.avi\")])\n",
    "        if not video_path:\n",
    "            return\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        self.tap_count = 0\n",
    "        self.prev_pred = 0\n",
    "        self.frame_queue.clear()\n",
    "        self.last_tap_time = time.time()\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            display_img = cv2.resize(rgb, (640, 480))\n",
    "            model_input_frame = cv2.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "            gray = cv2.cvtColor(model_input_frame, cv2.COLOR_RGB2GRAY)\n",
    "            diff = cv2.absdiff(gray, gray)  # placeholder for frame diff\n",
    "\n",
    "            if hasattr(self, 'prev_gray'):\n",
    "                diff = cv2.absdiff(self.prev_gray, gray)\n",
    "            self.prev_gray = gray\n",
    "\n",
    "            diff = np.expand_dims(diff, axis=-1)\n",
    "            diff = np.repeat(diff, 3, axis=-1)\n",
    "            diff = transform(diff)\n",
    "            self.frame_queue.append(diff)\n",
    "\n",
    "            if len(self.frame_queue) == SEQ_FRAMES:\n",
    "                sequence = torch.stack(list(self.frame_queue)).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(sequence)\n",
    "                    probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                    pred = np.argmax(probs)\n",
    "\n",
    "                current_time = time.time()\n",
    "                if (\n",
    "                    self.prev_pred == 0 and pred == 1 and\n",
    "                    (current_time - self.last_tap_time > self.min_interval)\n",
    "                ):\n",
    "                    self.tap_count += 1\n",
    "                    self.last_tap_time = current_time\n",
    "                    if beep: beep.play()\n",
    "\n",
    "                self.prev_pred = pred\n",
    "\n",
    "            img = Image.fromarray(display_img)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.canvas.imgtk = imgtk\n",
    "            self.canvas.configure(image=imgtk)\n",
    "            self.count_label.config(text=f\"Taps Detected: {self.tap_count}\")\n",
    "            self.root.update()\n",
    "\n",
    "        cap.release()\n",
    "        self.count_label.config(text=f\"Total Taps: {self.tap_count}\")\n",
    "\n",
    "# --- Run GUI ---\n",
    "root = tk.Tk()\n",
    "app = TapVideoApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", root.destroy)\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
