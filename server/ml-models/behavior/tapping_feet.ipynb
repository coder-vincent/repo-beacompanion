{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55c8154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision opencv-python matplotlib seaborn tqdm scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee680558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ef072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, folder, label, transform=None, seq_len=10):\n",
    "        self.transform = transform\n",
    "        self.seq_len = seq_len\n",
    "        self.label = label\n",
    "        self.samples = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(\".mp4\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def read_video(self, path):\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (64, 64))\n",
    "            if self.transform:\n",
    "                frame = self.transform(frame)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) < self.seq_len:\n",
    "            return None\n",
    "        idxs = np.linspace(0, len(frames) - 1, self.seq_len).astype(int)\n",
    "        return torch.stack([frames[i] for i in idxs])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.samples[idx]\n",
    "        frames = self.read_video(path)\n",
    "        while frames is None:\n",
    "            idx = (idx + 1) % len(self.samples)\n",
    "            path = self.samples[idx]\n",
    "            frames = self.read_video(path)\n",
    "        return frames, torch.tensor(self.label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27bdaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 520 | Test: 128\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "base = r\"C:\\Users\\julliana rose\\Documents\\4th Year\\Capstone\\BEA\\Fidgeting\\tapping_feet_v3\"\n",
    "\n",
    "train_data = [\n",
    "    VideoDataset(os.path.join(base, \"tapping/training\"), 1, transform),\n",
    "    VideoDataset(os.path.join(base, \"non-tapping/training\"), 0, transform)\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    VideoDataset(os.path.join(base, \"tapping/testing\"), 1, transform),\n",
    "    VideoDataset(os.path.join(base, \"non-tapping/testing\"), 0, transform)\n",
    "]\n",
    "\n",
    "train_dataset = ConcatDataset(train_data)\n",
    "test_dataset = ConcatDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)} | Test: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0dac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6426344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julliana rose\\Documents\\4th Year\\Capstone\\BEA\\Fidgeting\\tapping_feet_v3\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\julliana rose\\Documents\\4th Year\\Capstone\\BEA\\Fidgeting\\tapping_feet_v3\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 130/130 [02:12<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 72.4671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:04<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Loss: 40.4170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:08<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Loss: 25.3649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:08<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Loss: 22.1574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:08<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Loss: 16.4374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:07<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Loss: 22.8835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:06<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Loss: 13.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Loss: 13.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:00<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Loss: 15.7197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [02:13<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Loss: 18.0887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNLSTM().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22db8af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.98\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Non-Tapping       1.00      0.97      0.98        64\n",
      "     Tapping       0.97      1.00      0.98        64\n",
      "\n",
      "    accuracy                           0.98       128\n",
      "   macro avg       0.98      0.98      0.98       128\n",
      "weighted avg       0.98      0.98      0.98       128\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "print(f\"\\nAccuracy: {acc:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Non-Tapping\", \"Tapping\"]))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Non-Tapping\", \"Tapping\"], yticklabels=[\"Non-Tapping\", \"Tapping\"])\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66797f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as tapping_feet_mobilenet4.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"tapping_feet_mobilenet4.pth\")\n",
    "print(\"Model saved as tapping_feet_mobilenet4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3440cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: pillow in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: pygame in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (3.10.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jax->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python mediapipe pillow pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "990491f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (0.10.21)\n",
      "Requirement already satisfied: absl-py in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (25.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: jaxlib in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.6.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (3.10.3)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.12 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from jax->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julliana rose\\documents\\4th year\\capstone\\bea\\fidgeting\\tapping_feet_v3\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf931e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0, Probabilities: [0.63105756 0.36894238], Motion: 2.23\n",
      "Prediction: 0, Probabilities: [0.7325484 0.2674516], Motion: 15.03\n",
      "Prediction: 0, Probabilities: [0.8146798 0.1853202], Motion: 7.90\n",
      "Prediction: 0, Probabilities: [0.85934466 0.14065535], Motion: 4.49\n",
      "Prediction: 0, Probabilities: [0.89582753 0.10417242], Motion: 3.57\n",
      "Prediction: 0, Probabilities: [0.9160421  0.08395787], Motion: 13.84\n",
      "Prediction: 0, Probabilities: [0.92470384 0.07529611], Motion: 6.00\n",
      "Prediction: 0, Probabilities: [0.88156754 0.11843249], Motion: 3.86\n",
      "Prediction: 0, Probabilities: [0.8707811  0.12921892], Motion: 2.03\n",
      "Prediction: 0, Probabilities: [0.9185773  0.08142269], Motion: 3.03\n",
      "Prediction: 0, Probabilities: [0.92534953 0.07465044], Motion: 5.81\n",
      "Prediction: 0, Probabilities: [0.9309254  0.06907457], Motion: 1.59\n",
      "Prediction: 0, Probabilities: [0.94287276 0.05712721], Motion: 1.20\n",
      "Prediction: 0, Probabilities: [0.9425848  0.05741518], Motion: 7.28\n",
      "Prediction: 0, Probabilities: [0.9574905  0.04250948], Motion: 1.91\n",
      "Prediction: 0, Probabilities: [0.951748   0.04825195], Motion: 3.92\n",
      "Prediction: 0, Probabilities: [0.9370774  0.06292263], Motion: 2.68\n",
      "Prediction: 0, Probabilities: [0.95972764 0.04027232], Motion: 5.69\n",
      "Prediction: 0, Probabilities: [0.91565424 0.08434578], Motion: 7.23\n",
      "Prediction: 0, Probabilities: [0.94664675 0.05335325], Motion: 4.81\n",
      "Prediction: 0, Probabilities: [0.9490037  0.05099636], Motion: 0.80\n",
      "Prediction: 0, Probabilities: [0.92438936 0.07561058], Motion: 3.43\n",
      "Prediction: 0, Probabilities: [0.89425945 0.10574053], Motion: 2.79\n",
      "Prediction: 0, Probabilities: [0.8785295 0.1214705], Motion: 3.25\n",
      "Prediction: 0, Probabilities: [0.83878046 0.1612196 ], Motion: 2.69\n",
      "Prediction: 0, Probabilities: [0.822165   0.17783502], Motion: 2.40\n",
      "Prediction: 0, Probabilities: [0.849426   0.15057406], Motion: 3.21\n",
      "Prediction: 0, Probabilities: [0.7894254  0.21057457], Motion: 3.16\n",
      "Prediction: 0, Probabilities: [0.811195   0.18880498], Motion: 4.26\n",
      "Prediction: 0, Probabilities: [0.79769456 0.20230542], Motion: 7.21\n",
      "Prediction: 0, Probabilities: [0.87783813 0.1221619 ], Motion: 9.13\n",
      "Prediction: 0, Probabilities: [0.91491693 0.08508313], Motion: 1.69\n",
      "Prediction: 0, Probabilities: [0.91678375 0.08321626], Motion: 3.73\n",
      "Prediction: 0, Probabilities: [0.92435044 0.07564959], Motion: 4.89\n",
      "Prediction: 0, Probabilities: [0.91387147 0.08612853], Motion: 1.75\n",
      "Prediction: 0, Probabilities: [0.89251524 0.10748474], Motion: 1.71\n",
      "Prediction: 0, Probabilities: [0.8894414  0.11055867], Motion: 1.01\n",
      "Prediction: 0, Probabilities: [0.89364755 0.10635243], Motion: 2.11\n",
      "Prediction: 0, Probabilities: [0.9013751  0.09862489], Motion: 0.52\n",
      "Prediction: 0, Probabilities: [0.90351224 0.09648775], Motion: 0.00\n",
      "Prediction: 0, Probabilities: [0.905339   0.09466099], Motion: 2.63\n",
      "Prediction: 0, Probabilities: [0.9081735  0.09182646], Motion: 1.48\n",
      "Prediction: 0, Probabilities: [0.90674096 0.09325899], Motion: 2.50\n",
      "Prediction: 0, Probabilities: [0.93196267 0.06803734], Motion: 5.27\n",
      "Prediction: 0, Probabilities: [0.8982283  0.10177173], Motion: 2.25\n",
      "Prediction: 0, Probabilities: [0.93449163 0.06550833], Motion: 0.70\n",
      "Prediction: 0, Probabilities: [0.93879116 0.06120884], Motion: 0.40\n",
      "Prediction: 0, Probabilities: [0.9580066  0.04199338], Motion: 1.90\n",
      "Prediction: 0, Probabilities: [0.9558427 0.0441574], Motion: 5.56\n",
      "Prediction: 0, Probabilities: [0.9485028  0.05149725], Motion: 1.92\n",
      "Prediction: 0, Probabilities: [0.93352985 0.06647015], Motion: 2.63\n",
      "Prediction: 0, Probabilities: [0.9335649  0.06643515], Motion: 2.37\n",
      "Prediction: 0, Probabilities: [0.94827926 0.05172073], Motion: 0.85\n",
      "Prediction: 0, Probabilities: [0.95766664 0.04233341], Motion: 3.43\n",
      "Prediction: 0, Probabilities: [0.9426275  0.05737248], Motion: 1.01\n",
      "Prediction: 0, Probabilities: [0.9094647  0.09053524], Motion: 1.58\n",
      "Prediction: 0, Probabilities: [0.8915632  0.10843689], Motion: 3.75\n",
      "Prediction: 0, Probabilities: [0.8933322 0.1066678], Motion: 2.37\n",
      "Prediction: 0, Probabilities: [0.91660917 0.08339083], Motion: 1.27\n",
      "Prediction: 0, Probabilities: [0.9264509  0.07354911], Motion: 3.26\n",
      "Prediction: 0, Probabilities: [0.9295042  0.07049587], Motion: 3.24\n",
      "Prediction: 0, Probabilities: [0.91399914 0.08600087], Motion: 3.39\n",
      "Prediction: 0, Probabilities: [0.89171356 0.10828643], Motion: 1.46\n",
      "Prediction: 0, Probabilities: [0.9325758  0.06742415], Motion: 3.13\n",
      "Prediction: 0, Probabilities: [0.9523893  0.04761064], Motion: 0.55\n",
      "Prediction: 0, Probabilities: [0.9505588  0.04944127], Motion: 1.75\n",
      "Prediction: 0, Probabilities: [0.93759805 0.06240196], Motion: 2.28\n",
      "Prediction: 0, Probabilities: [0.93360883 0.06639111], Motion: 2.40\n",
      "Prediction: 0, Probabilities: [0.92877924 0.07122075], Motion: 2.90\n",
      "Prediction: 0, Probabilities: [0.92754835 0.07245173], Motion: 0.99\n",
      "Prediction: 0, Probabilities: [0.92319196 0.07680796], Motion: 3.82\n",
      "Prediction: 0, Probabilities: [0.91527224 0.08472775], Motion: 2.27\n",
      "Prediction: 0, Probabilities: [0.9203562  0.07964377], Motion: 5.17\n",
      "Prediction: 0, Probabilities: [0.89893484 0.10106514], Motion: 2.83\n",
      "Prediction: 0, Probabilities: [0.8777008  0.12229917], Motion: 4.11\n",
      "Prediction: 0, Probabilities: [0.85028327 0.14971676], Motion: 0.00\n",
      "Prediction: 0, Probabilities: [0.83024997 0.16975   ], Motion: 2.85\n",
      "Prediction: 0, Probabilities: [0.841752 0.158248], Motion: 2.55\n",
      "Prediction: 0, Probabilities: [0.86631125 0.13368876], Motion: 0.92\n",
      "Prediction: 0, Probabilities: [0.8294386  0.17056139], Motion: 2.55\n",
      "Prediction: 0, Probabilities: [0.7604965 0.2395035], Motion: 2.88\n",
      "Prediction: 0, Probabilities: [0.7710085  0.22899154], Motion: 2.99\n",
      "Prediction: 0, Probabilities: [0.7803648  0.21963517], Motion: 1.88\n",
      "Prediction: 0, Probabilities: [0.76444966 0.23555033], Motion: 2.69\n",
      "Prediction: 0, Probabilities: [0.84575474 0.15424535], Motion: 3.64\n",
      "Prediction: 0, Probabilities: [0.8055587  0.19444133], Motion: 3.41\n",
      "Prediction: 0, Probabilities: [0.81364584 0.1863542 ], Motion: 1.99\n",
      "Prediction: 0, Probabilities: [0.8319216  0.16807842], Motion: 0.75\n",
      "Prediction: 0, Probabilities: [0.76118785 0.23881222], Motion: 1.31\n",
      "Prediction: 0, Probabilities: [0.8434235  0.15657651], Motion: 4.30\n",
      "Prediction: 0, Probabilities: [0.80630046 0.1936996 ], Motion: 1.91\n",
      "Prediction: 0, Probabilities: [0.7799714  0.22002858], Motion: 1.26\n",
      "Prediction: 0, Probabilities: [0.74375534 0.25624466], Motion: 0.47\n",
      "Prediction: 0, Probabilities: [0.7587316  0.24126837], Motion: 1.44\n",
      "Prediction: 0, Probabilities: [0.7578703  0.24212971], Motion: 1.51\n",
      "Prediction: 0, Probabilities: [0.76488286 0.23511714], Motion: 0.36\n",
      "Prediction: 0, Probabilities: [0.7906123  0.20938773], Motion: 1.80\n",
      "Prediction: 0, Probabilities: [0.8840734 0.1159266], Motion: 0.46\n",
      "Prediction: 0, Probabilities: [0.80249923 0.19750077], Motion: 0.81\n",
      "Prediction: 0, Probabilities: [0.72425    0.27574992], Motion: 2.74\n",
      "Prediction: 0, Probabilities: [0.66371495 0.33628508], Motion: 0.53\n",
      "Prediction: 0, Probabilities: [0.7574015  0.24259852], Motion: 4.53\n",
      "Prediction: 0, Probabilities: [0.81929106 0.18070894], Motion: 4.39\n",
      "Prediction: 0, Probabilities: [0.88777584 0.11222418], Motion: 1.33\n",
      "Prediction: 0, Probabilities: [0.9005393  0.09946078], Motion: 3.27\n",
      "Prediction: 0, Probabilities: [0.91177607 0.08822393], Motion: 2.00\n",
      "Prediction: 0, Probabilities: [0.92617023 0.07382983], Motion: 0.82\n",
      "Prediction: 0, Probabilities: [0.91891503 0.08108494], Motion: 4.78\n",
      "Prediction: 0, Probabilities: [0.91236144 0.08763858], Motion: 2.20\n",
      "Prediction: 0, Probabilities: [0.9202909  0.07970905], Motion: 0.83\n",
      "Prediction: 0, Probabilities: [0.9398029  0.06019716], Motion: 5.39\n",
      "Prediction: 0, Probabilities: [0.93513197 0.06486804], Motion: 8.68\n",
      "Prediction: 0, Probabilities: [0.9384951 0.0615049], Motion: 9.38\n",
      "Prediction: 0, Probabilities: [0.95787513 0.04212482], Motion: 8.44\n",
      "Prediction: 0, Probabilities: [0.94644606 0.05355397], Motion: 15.11\n",
      "Prediction: 0, Probabilities: [0.9319746 0.0680254], Motion: 3.15\n",
      "Prediction: 0, Probabilities: [0.9553775  0.04462246], Motion: 16.57\n",
      "Prediction: 0, Probabilities: [0.93882126 0.06117876], Motion: 19.26\n",
      "Prediction: 0, Probabilities: [0.91412    0.08587999], Motion: 11.88\n"
     ]
    }
   ],
   "source": [
    "# Testing w/ Skeleton and Tap Count Only (No Time, No ADHD Likelihood)\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- Model Definition ---\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "# --- Setup ---\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"tapping_feet_mobilenet2.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_tracker = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class TapCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"BEA - Total Tap Counter\")\n",
    "\n",
    "        self.canvas = tk.Label(root)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.count_label = tk.Label(root, text=\"Total Taps: 0\", font=(\"Arial\", 18))\n",
    "        self.count_label.pack(pady=5)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(1)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "        self.frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "        self.tap_count = 0\n",
    "        self.last_tap_time = time.time()\n",
    "        self.min_interval = 0.3\n",
    "        self.prev_gray = None\n",
    "\n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(10, self.update_frame)\n",
    "            return\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        display_img = cv2.resize(rgb, (640, 480))\n",
    "        model_input_frame = display_img.copy()\n",
    "\n",
    "        pose_results = pose_tracker.process(display_img)\n",
    "        pose_valid = False\n",
    "\n",
    "        if pose_results.pose_landmarks:\n",
    "            h, w, _ = display_img.shape\n",
    "            lm = pose_results.pose_landmarks.landmark\n",
    "            required_landmarks = [\n",
    "                mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "                mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "                mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "                mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "            ]\n",
    "            pose_valid = all(lm[i].visibility > 0.5 for i in required_landmarks)\n",
    "\n",
    "            # --- Draw Skeleton for Leg Landmarks ---\n",
    "            def get_coord(index):\n",
    "                point = lm[index]\n",
    "                return int(point.x * w), int(point.y * h)\n",
    "\n",
    "            LEG_PAIRS = [\n",
    "                (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.LEFT_HEEL),\n",
    "                (mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.LEFT_FOOT_INDEX),\n",
    "                (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ANKLE, mp_pose.PoseLandmark.RIGHT_HEEL),\n",
    "                (mp_pose.PoseLandmark.RIGHT_HEEL, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX)\n",
    "            ]\n",
    "\n",
    "            for start, end in LEG_PAIRS:\n",
    "                x1, y1 = get_coord(start)\n",
    "                x2, y2 = get_coord(end)\n",
    "                cv2.line(display_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.circle(display_img, (x1, y1), 6, (0, 255, 0), -1)\n",
    "                cv2.circle(display_img, (x2, y2), 6, (0, 255, 0), -1)\n",
    "\n",
    "        # --- Motion Detection ---\n",
    "        gray = cv2.cvtColor(model_input_frame, cv2.COLOR_RGB2GRAY)\n",
    "        gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray\n",
    "            motion = 0\n",
    "        else:\n",
    "            diff = cv2.absdiff(self.prev_gray, gray)\n",
    "            motion = np.sum(diff) / (IMG_SIZE * IMG_SIZE)\n",
    "            self.prev_gray = gray\n",
    "\n",
    "        # --- Frame Sequence Logic ---\n",
    "        if pose_valid:\n",
    "            resized_frame = cv2.resize(model_input_frame, (IMG_SIZE, IMG_SIZE))\n",
    "            tensor = transform(resized_frame)\n",
    "            self.frame_queue.append(tensor)\n",
    "\n",
    "        if pose_valid and len(self.frame_queue) == SEQ_FRAMES:\n",
    "            sequence = torch.stack(list(self.frame_queue)).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(sequence)\n",
    "                probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                pred = np.argmax(probs)\n",
    "\n",
    "            current_time = time.time()\n",
    "            tap_conf = probs[1]\n",
    "\n",
    "            print(f\"Prediction: {pred}, Probabilities: {probs}, Motion: {motion:.2f}\")\n",
    "\n",
    "            if pred == 1 and tap_conf > 0.8 and motion > 2.0 and (current_time - self.last_tap_time > self.min_interval):\n",
    "                self.tap_count += 1\n",
    "                self.last_tap_time = current_time\n",
    "                self.count_label.config(text=f\"Total Taps: {self.tap_count}\")\n",
    "\n",
    "        img = Image.fromarray(display_img)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.canvas.imgtk = imgtk\n",
    "        self.canvas.configure(image=imgtk)\n",
    "\n",
    "        self.root.after(30, self.update_frame)\n",
    "\n",
    "    def on_close(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "# --- Run GUI ---\n",
    "root = tk.Tk()\n",
    "app = TapCounterApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", app.on_close)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "409ca543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1, Probabilities: [0.03021327 0.96978676], Motion: 5.48\n",
      "Prediction: 1, Probabilities: [0.02749104 0.9725089 ], Motion: 1.20\n",
      "Prediction: 1, Probabilities: [0.03176625 0.96823376], Motion: 2.27\n",
      "Prediction: 1, Probabilities: [0.02248968 0.9775103 ], Motion: 0.79\n",
      "Prediction: 1, Probabilities: [0.03058247 0.9694175 ], Motion: 1.76\n",
      "Prediction: 1, Probabilities: [0.03166133 0.9683387 ], Motion: 4.27\n",
      "Prediction: 1, Probabilities: [0.04174366 0.95825636], Motion: 2.48\n",
      "Prediction: 1, Probabilities: [0.04475887 0.9552412 ], Motion: 1.58\n",
      "Prediction: 1, Probabilities: [0.04107185 0.9589282 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.05050818 0.9494918 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03027328 0.9697267 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03031206 0.969688  ], Motion: 3.64\n",
      "Prediction: 1, Probabilities: [0.03565858 0.9643414 ], Motion: 1.60\n",
      "Prediction: 1, Probabilities: [0.03558364 0.9644163 ], Motion: 3.92\n",
      "Prediction: 1, Probabilities: [0.04127754 0.9587225 ], Motion: 3.12\n",
      "Prediction: 1, Probabilities: [0.0403666  0.95963335], Motion: 1.65\n",
      "Prediction: 1, Probabilities: [0.03178082 0.96821916], Motion: 2.59\n",
      "Prediction: 1, Probabilities: [0.03842107 0.96157897], Motion: 2.84\n",
      "Prediction: 1, Probabilities: [0.04972054 0.9502795 ], Motion: 3.46\n",
      "Prediction: 1, Probabilities: [0.06571721 0.9342827 ], Motion: 2.82\n",
      "Prediction: 1, Probabilities: [0.13516286 0.8648371 ], Motion: 3.68\n",
      "Prediction: 1, Probabilities: [0.15396965 0.8460303 ], Motion: 2.79\n",
      "Prediction: 1, Probabilities: [0.15498044 0.8450196 ], Motion: 1.88\n",
      "Prediction: 1, Probabilities: [0.10126043 0.8987396 ], Motion: 0.98\n",
      "Prediction: 1, Probabilities: [0.06770728 0.93229276], Motion: 1.24\n",
      "Prediction: 1, Probabilities: [0.06662555 0.93337446], Motion: 0.82\n",
      "Prediction: 1, Probabilities: [0.05881605 0.941184  ], Motion: 0.54\n",
      "Prediction: 1, Probabilities: [0.03616442 0.9638356 ], Motion: 0.25\n",
      "Prediction: 1, Probabilities: [0.02416382 0.9758362 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02621347 0.97378653], Motion: 1.23\n",
      "Prediction: 1, Probabilities: [0.03080546 0.9691945 ], Motion: 2.05\n",
      "Prediction: 1, Probabilities: [0.02635331 0.9736467 ], Motion: 2.66\n",
      "Prediction: 1, Probabilities: [0.01284049 0.9871595 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01609145 0.9839086 ], Motion: 3.55\n",
      "Prediction: 1, Probabilities: [0.01663735 0.9833626 ], Motion: 1.27\n",
      "Prediction: 1, Probabilities: [0.03299985 0.9670001 ], Motion: 1.85\n",
      "Prediction: 1, Probabilities: [0.03790801 0.962092  ], Motion: 2.67\n",
      "Prediction: 1, Probabilities: [0.03681173 0.9631883 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.05576047 0.94423956], Motion: 3.12\n",
      "Prediction: 1, Probabilities: [0.06193787 0.9380621 ], Motion: 1.74\n",
      "Prediction: 1, Probabilities: [0.05488608 0.9451139 ], Motion: 2.74\n",
      "Prediction: 1, Probabilities: [0.06419565 0.9358043 ], Motion: 3.26\n",
      "Prediction: 1, Probabilities: [0.10830092 0.8916991 ], Motion: 1.55\n",
      "Prediction: 1, Probabilities: [0.13013567 0.86986434], Motion: 3.22\n",
      "Prediction: 1, Probabilities: [0.20689112 0.7931089 ], Motion: 1.37\n",
      "Prediction: 1, Probabilities: [0.09718139 0.9028186 ], Motion: 0.59\n",
      "Prediction: 1, Probabilities: [0.08996432 0.91003567], Motion: 1.34\n",
      "Prediction: 1, Probabilities: [0.12881516 0.8711848 ], Motion: 0.69\n",
      "Prediction: 1, Probabilities: [0.07910622 0.9208937 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.05075324 0.9492468 ], Motion: 0.86\n",
      "Prediction: 1, Probabilities: [0.03372222 0.9662778 ], Motion: 0.31\n",
      "Prediction: 1, Probabilities: [0.0552594 0.9447406], Motion: 1.65\n",
      "Prediction: 1, Probabilities: [0.06346472 0.93653524], Motion: 7.86\n",
      "Prediction: 1, Probabilities: [0.04873079 0.95126927], Motion: 2.59\n",
      "Prediction: 1, Probabilities: [0.03621119 0.96378887], Motion: 13.50\n",
      "Prediction: 1, Probabilities: [0.03507703 0.96492296], Motion: 3.98\n",
      "Prediction: 1, Probabilities: [0.04358485 0.9564151 ], Motion: 22.57\n",
      "Prediction: 1, Probabilities: [0.03840576 0.9615943 ], Motion: 17.93\n",
      "Prediction: 1, Probabilities: [0.10063723 0.89936274], Motion: 35.70\n",
      "Prediction: 1, Probabilities: [0.11947824 0.8805217 ], Motion: 13.72\n",
      "Prediction: 1, Probabilities: [0.13236454 0.8676354 ], Motion: 12.43\n",
      "Prediction: 1, Probabilities: [0.08558828 0.91441166], Motion: 14.11\n"
     ]
    }
   ],
   "source": [
    "# Modified version: Removed time logic, count taps only\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import mediapipe as mp\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"tapping_feet_mobilenet3.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_tracker = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class TapCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"BEA - Total Tapping Counter\")\n",
    "\n",
    "        self.canvas = tk.Label(root)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.count_label = tk.Label(root, text=\"Total Taps: 0\", font=(\"Arial\", 18))\n",
    "        self.count_label.pack(pady=5)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(1)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "        self.frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "        self.tap_count = 0\n",
    "        self.last_tap_time = 0\n",
    "        self.min_interval = 0.3\n",
    "        self.prev_gray = None\n",
    "\n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(10, self.update_frame)\n",
    "            return\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        display_img = cv2.resize(rgb, (640, 480))\n",
    "        model_input_frame = display_img.copy()\n",
    "\n",
    "        pose_results = pose_tracker.process(display_img)\n",
    "        pose_valid = False\n",
    "\n",
    "        if pose_results.pose_landmarks:\n",
    "            h, w, _ = display_img.shape\n",
    "            lm = pose_results.pose_landmarks.landmark\n",
    "            required_landmarks = [\n",
    "                mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "                mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "                mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "                mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "            ]\n",
    "            pose_valid = all(lm[i].visibility > 0.5 for i in required_landmarks)\n",
    "\n",
    "            def get_coord(index):\n",
    "                point = lm[index]\n",
    "                return int(point.x * w), int(point.y * h)\n",
    "\n",
    "            LEG_PAIRS = [\n",
    "                (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.LEFT_HEEL),\n",
    "                (mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.LEFT_FOOT_INDEX),\n",
    "                (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ANKLE, mp_pose.PoseLandmark.RIGHT_HEEL),\n",
    "                (mp_pose.PoseLandmark.RIGHT_HEEL, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX)\n",
    "            ]\n",
    "\n",
    "            for start, end in LEG_PAIRS:\n",
    "                x1, y1 = get_coord(start)\n",
    "                x2, y2 = get_coord(end)\n",
    "                cv2.line(display_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.circle(display_img, (x1, y1), 6, (0, 255, 0), -1)\n",
    "                cv2.circle(display_img, (x2, y2), 6, (0, 255, 0), -1)\n",
    "\n",
    "        img = Image.fromarray(display_img)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.canvas.imgtk = imgtk\n",
    "        self.canvas.configure(image=imgtk)\n",
    "\n",
    "        if pose_valid:\n",
    "            gray = cv2.cvtColor(model_input_frame, cv2.COLOR_RGB2GRAY)\n",
    "            if self.prev_gray is None:\n",
    "                self.prev_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "                self.root.after(30, self.update_frame)\n",
    "                return\n",
    "\n",
    "            curr_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "            diff = cv2.absdiff(self.prev_gray, curr_gray)\n",
    "            self.prev_gray = curr_gray\n",
    "            motion = np.mean(diff)\n",
    "\n",
    "            diff = np.expand_dims(diff, axis=-1)\n",
    "            diff = np.repeat(diff, 3, axis=-1)\n",
    "            diff = transform(diff)\n",
    "            self.frame_queue.append(diff)\n",
    "\n",
    "            if len(self.frame_queue) == SEQ_FRAMES:\n",
    "                sequence = torch.stack(list(self.frame_queue)).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(sequence)\n",
    "                    probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                    pred = np.argmax(probs)\n",
    "\n",
    "                tap_conf = probs[1]\n",
    "                print(f\"Prediction: {pred}, Probabilities: {probs}, Motion: {motion:.2f}\")\n",
    "\n",
    "                current_time = time.time()\n",
    "                if pred == 1 and tap_conf > 0.8 and motion > 2.0 and (current_time - self.last_tap_time > self.min_interval):\n",
    "                    self.tap_count += 1\n",
    "                    self.last_tap_time = current_time\n",
    "                    self.count_label.config(text=f\"Total Taps: {self.tap_count}\")\n",
    "\n",
    "        self.root.after(30, self.update_frame)\n",
    "\n",
    "    def on_close(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "root = tk.Tk()\n",
    "app = TapCounterApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", app.on_close)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9527d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1, Probabilities: [0.08268207 0.9173179 ], Motion: 1.06\n",
      "Prediction: 1, Probabilities: [0.05074404 0.94925594], Motion: 4.86\n",
      "Prediction: 1, Probabilities: [0.07214639 0.92785364], Motion: 0.94\n",
      "Prediction: 1, Probabilities: [0.06069835 0.9393016 ], Motion: 4.39\n",
      "Prediction: 1, Probabilities: [0.06894434 0.9310556 ], Motion: 1.21\n",
      "Prediction: 1, Probabilities: [0.0648849 0.9351151], Motion: 11.02\n",
      "Prediction: 1, Probabilities: [0.07363252 0.9263675 ], Motion: 7.52\n",
      "Prediction: 1, Probabilities: [0.05621717 0.94378287], Motion: 5.26\n",
      "Prediction: 1, Probabilities: [0.08979587 0.9102042 ], Motion: 1.29\n",
      "Prediction: 1, Probabilities: [0.07172198 0.928278  ], Motion: 3.06\n",
      "Prediction: 1, Probabilities: [0.05230408 0.9476959 ], Motion: 1.60\n",
      "Prediction: 1, Probabilities: [0.07829361 0.9217063 ], Motion: 0.62\n",
      "Prediction: 1, Probabilities: [0.06689916 0.9331008 ], Motion: 6.79\n",
      "Prediction: 1, Probabilities: [0.05089784 0.94910216], Motion: 6.43\n",
      "Prediction: 1, Probabilities: [0.05656534 0.9434347 ], Motion: 11.69\n",
      "Prediction: 1, Probabilities: [0.08763162 0.9123684 ], Motion: 3.26\n",
      "Prediction: 1, Probabilities: [0.07364167 0.9263583 ], Motion: 12.54\n",
      "Prediction: 1, Probabilities: [0.08473641 0.9152636 ], Motion: 3.50\n",
      "Prediction: 1, Probabilities: [0.07157123 0.9284287 ], Motion: 3.03\n"
     ]
    }
   ],
   "source": [
    "#Testing of Model 2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- Model Definition ---\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "# --- Setup ---\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"tapping_feet_mobilenet2.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Init MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_tracker = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Frame transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- GUI App ---\n",
    "class TapCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"BEA - Foot Tapping Counter (Per Minute Display)\")\n",
    "\n",
    "        self.canvas = tk.Label(root)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.count_label = tk.Label(root, text=\"Taps this minute: 0\", font=(\"Arial\", 18))\n",
    "        self.count_label.pack(pady=5)\n",
    "\n",
    "        self.total_label = tk.Label(root, text=\"Total Minutes Logged: 0\", font=(\"Arial\", 14))\n",
    "        self.total_label.pack(pady=5)\n",
    "\n",
    "        self.advisory_label = tk.Label(root, text=\"ADHD Likelihood: Not enough data\", font=(\"Arial\", 14), fg=\"blue\")\n",
    "        self.advisory_label.pack(pady=5)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(1)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "        self.frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "        self.tap_count = 0\n",
    "        self.total_minutes = 0\n",
    "        self.last_tap_time = time.time()\n",
    "        self.min_interval = 0.3\n",
    "        self.prev_pred = 0\n",
    "        self.prev_gray = None\n",
    "\n",
    "        self.start_time = time.time()\n",
    "        self.last_logged_minute = 0\n",
    "\n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(10, self.update_frame)\n",
    "            return\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        display_img = cv2.resize(rgb, (640, 480))\n",
    "        model_input_frame = display_img.copy()\n",
    "\n",
    "        pose_results = pose_tracker.process(display_img)\n",
    "        pose_valid = False\n",
    "\n",
    "        if pose_results.pose_landmarks:\n",
    "            h, w, _ = display_img.shape\n",
    "            lm = pose_results.pose_landmarks.landmark\n",
    "\n",
    "            required_landmarks = [\n",
    "                mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "                mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "                mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "                mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "            ]\n",
    "\n",
    "            pose_valid = all(lm[i].visibility > 0.5 for i in required_landmarks)\n",
    "\n",
    "            def get_coord(index):\n",
    "                point = lm[index]\n",
    "                return int(point.x * w), int(point.y * h)\n",
    "\n",
    "            LEG_PAIRS = [\n",
    "                (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.LEFT_HEEL),\n",
    "                (mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.LEFT_FOOT_INDEX),\n",
    "                (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ANKLE, mp_pose.PoseLandmark.RIGHT_HEEL),\n",
    "                (mp_pose.PoseLandmark.RIGHT_HEEL, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX)\n",
    "            ]\n",
    "\n",
    "            for start, end in LEG_PAIRS:\n",
    "                x1, y1 = get_coord(start)\n",
    "                x2, y2 = get_coord(end)\n",
    "                cv2.line(display_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.circle(display_img, (x1, y1), 6, (0, 255, 0), -1)\n",
    "                cv2.circle(display_img, (x2, y2), 6, (0, 255, 0), -1)\n",
    "\n",
    "        img = Image.fromarray(display_img)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.canvas.imgtk = imgtk\n",
    "        self.canvas.configure(image=imgtk)\n",
    "\n",
    "        if pose_valid:\n",
    "            gray = cv2.cvtColor(model_input_frame, cv2.COLOR_RGB2GRAY)\n",
    "            if self.prev_gray is None:\n",
    "                self.prev_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "                self.root.after(30, self.update_frame)\n",
    "                return\n",
    "\n",
    "            curr_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "            diff = cv2.absdiff(self.prev_gray, curr_gray)\n",
    "            self.prev_gray = curr_gray\n",
    "            motion = np.mean(diff)\n",
    "\n",
    "            diff = np.expand_dims(diff, axis=-1)\n",
    "            diff = np.repeat(diff, 3, axis=-1)\n",
    "            diff = transform(diff)\n",
    "            self.frame_queue.append(diff)\n",
    "\n",
    "            if len(self.frame_queue) == SEQ_FRAMES:\n",
    "                sequence = torch.stack(list(self.frame_queue)).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(sequence)\n",
    "                    probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                    pred = np.argmax(probs)\n",
    "\n",
    "                tap_conf = probs[1]\n",
    "                current_time = time.time()\n",
    "                print(f\"Prediction: {pred}, Probabilities: {probs}, Motion: {motion:.2f}\")\n",
    "\n",
    "                if pred == 1 and tap_conf > 0.8 and motion > 2.0 and (current_time - self.last_tap_time > self.min_interval):\n",
    "                    self.tap_count += 1\n",
    "                    self.last_tap_time = current_time\n",
    "                    self.count_label.config(text=f\"Taps this minute: {self.tap_count}\")\n",
    "\n",
    "        elapsed_minutes = int((time.time() - self.start_time) // 60)\n",
    "        if elapsed_minutes > self.last_logged_minute:\n",
    "            self.last_logged_minute = elapsed_minutes\n",
    "            self.total_minutes += 1\n",
    "\n",
    "            if self.tap_count <= 1:\n",
    "                advisory = \"Least likely to have ADHD.\"\n",
    "            elif 2 <= self.tap_count <= 4:\n",
    "                advisory = \"Moderately likely to have ADHD.\"\n",
    "            else:\n",
    "                advisory = \"Most likely to have ADHD.\"\n",
    "\n",
    "            self.count_label.config(text=f\"Taps this minute: 0\")\n",
    "            self.total_label.config(text=f\"Total Minutes Logged: {self.total_minutes}\")\n",
    "            self.advisory_label.config(text=f\"ADHD Likelihood: {advisory}\")\n",
    "            self.tap_count = 0\n",
    "\n",
    "        self.root.after(30, self.update_frame)\n",
    "\n",
    "    def on_close(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "# --- Run GUI ---\n",
    "root = tk.Tk()\n",
    "app = TapCounterApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", app.on_close)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1, Probabilities: [0.03224593 0.967754  ], Motion: 5.24\n",
      "Prediction: 1, Probabilities: [0.03948824 0.96051174], Motion: 5.63\n",
      "Prediction: 1, Probabilities: [0.03415012 0.9658499 ], Motion: 4.44\n",
      "Prediction: 1, Probabilities: [0.03184559 0.96815443], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03316423 0.96683574], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01890635 0.9810937 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0121201  0.98787993], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01991499 0.98008496], Motion: 2.46\n",
      "Prediction: 1, Probabilities: [0.01307192 0.98692805], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01879694 0.981203  ], Motion: 1.14\n",
      "Prediction: 1, Probabilities: [0.01667376 0.98332626], Motion: 7.69\n",
      "Prediction: 1, Probabilities: [0.02116877 0.97883123], Motion: 2.27\n",
      "Prediction: 1, Probabilities: [0.01897105 0.981029  ], Motion: 0.79\n",
      "Prediction: 1, Probabilities: [0.03102058 0.9689794 ], Motion: 1.71\n",
      "Prediction: 1, Probabilities: [0.04916067 0.95083934], Motion: 1.01\n",
      "Prediction: 1, Probabilities: [0.08809481 0.9119052 ], Motion: 1.05\n",
      "Prediction: 1, Probabilities: [0.08028579 0.91971415], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06419604 0.9358039 ], Motion: 1.36\n",
      "Prediction: 1, Probabilities: [0.08825542 0.9117446 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06301032 0.93698967], Motion: 0.75\n",
      "Prediction: 1, Probabilities: [0.04751932 0.9524807 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04157945 0.9584205 ], Motion: 0.28\n",
      "Prediction: 1, Probabilities: [0.02840739 0.9715926 ], Motion: 0.32\n",
      "Prediction: 1, Probabilities: [0.01620031 0.9837997 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01258034 0.98741966], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01540751 0.9845925 ], Motion: 0.47\n",
      "Prediction: 1, Probabilities: [0.01470323 0.9852968 ], Motion: 0.45\n",
      "Prediction: 1, Probabilities: [0.0124448 0.9875552], Motion: 0.21\n",
      "Prediction: 1, Probabilities: [0.0101216 0.9898784], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01081647 0.98918355], Motion: 0.30\n",
      "Prediction: 1, Probabilities: [0.01149806 0.9885019 ], Motion: 0.30\n",
      "Prediction: 1, Probabilities: [0.0096384 0.9903616], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00959878 0.9904012 ], Motion: 0.17\n",
      "Prediction: 1, Probabilities: [0.01071543 0.9892846 ], Motion: 0.18\n",
      "Prediction: 1, Probabilities: [0.0099199  0.99008006], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01440732 0.98559266], Motion: 1.52\n",
      "Prediction: 1, Probabilities: [0.01059255 0.9894075 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01693942 0.98306054], Motion: 1.48\n",
      "Prediction: 1, Probabilities: [0.01821114 0.9817888 ], Motion: 1.55\n",
      "Prediction: 1, Probabilities: [0.02651443 0.9734856 ], Motion: 1.07\n",
      "Prediction: 1, Probabilities: [0.02179804 0.9782019 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02476654 0.97523344], Motion: 0.43\n",
      "Prediction: 1, Probabilities: [0.01916444 0.98083556], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03158504 0.96841496], Motion: 1.21\n",
      "Prediction: 1, Probabilities: [0.0575938 0.9424062], Motion: 1.31\n",
      "Prediction: 1, Probabilities: [0.02953753 0.9704625 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06713495 0.932865  ], Motion: 1.36\n",
      "Prediction: 1, Probabilities: [0.03135462 0.96864533], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03232966 0.9676703 ], Motion: 1.47\n",
      "Prediction: 1, Probabilities: [0.02437802 0.97562206], Motion: 0.15\n",
      "Prediction: 1, Probabilities: [0.02168729 0.97831273], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0199976 0.9800024], Motion: 0.18\n",
      "Prediction: 1, Probabilities: [0.02237589 0.97762406], Motion: 0.29\n",
      "Prediction: 1, Probabilities: [0.01398221 0.9860178 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01299951 0.98700047], Motion: 0.34\n",
      "Prediction: 1, Probabilities: [0.01371905 0.9862809 ], Motion: 0.16\n",
      "Prediction: 1, Probabilities: [0.01088357 0.9891164 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01096147 0.98903847], Motion: 0.21\n",
      "Prediction: 1, Probabilities: [0.01124705 0.98875296], Motion: 0.17\n",
      "Prediction: 1, Probabilities: [0.01286259 0.98713744], Motion: 0.19\n",
      "Prediction: 1, Probabilities: [0.0141006 0.9858994], Motion: 1.81\n",
      "Prediction: 1, Probabilities: [0.01073169 0.98926824], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00988754 0.9901125 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01242005 0.98758   ], Motion: 9.03\n",
      "Prediction: 1, Probabilities: [0.01094121 0.9890588 ], Motion: 7.23\n",
      "Prediction: 1, Probabilities: [0.00852552 0.9914745 ], Motion: 9.61\n",
      "Prediction: 1, Probabilities: [0.00822528 0.9917747 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01114678 0.9888532 ], Motion: 4.17\n",
      "Prediction: 1, Probabilities: [0.01325766 0.9867423 ], Motion: 8.23\n",
      "Prediction: 1, Probabilities: [0.02239779 0.9776022 ], Motion: 3.44\n",
      "Prediction: 1, Probabilities: [0.01564612 0.9843539 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01557481 0.9844252 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0180908  0.98190916], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02952485 0.9704752 ], Motion: 4.78\n",
      "Prediction: 1, Probabilities: [0.02182521 0.9781748 ], Motion: 1.20\n",
      "Prediction: 1, Probabilities: [0.01700136 0.98299867], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03548742 0.9645126 ], Motion: 2.09\n",
      "Prediction: 1, Probabilities: [0.02891361 0.9710863 ], Motion: 0.67\n",
      "Prediction: 1, Probabilities: [0.02327416 0.9767259 ], Motion: 0.62\n",
      "Prediction: 1, Probabilities: [0.01778286 0.9822172 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01764271 0.98235726], Motion: 0.45\n",
      "Prediction: 1, Probabilities: [0.02041415 0.9795858 ], Motion: 0.24\n",
      "Prediction: 1, Probabilities: [0.01893177 0.9810682 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01413527 0.98586476], Motion: 0.25\n",
      "Prediction: 1, Probabilities: [0.01343993 0.9865601 ], Motion: 0.24\n",
      "Prediction: 1, Probabilities: [0.01296358 0.9870364 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01268606 0.9873139 ], Motion: 0.32\n",
      "Prediction: 1, Probabilities: [0.01088033 0.98911965], Motion: 0.16\n",
      "Prediction: 1, Probabilities: [0.00993539 0.9900647 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00943133 0.9905687 ], Motion: 1.49\n",
      "Prediction: 1, Probabilities: [0.01359257 0.9864074 ], Motion: 1.14\n",
      "Prediction: 1, Probabilities: [0.0131054 0.9868946], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01214775 0.9878522 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01143996 0.98856   ], Motion: 1.06\n",
      "Prediction: 1, Probabilities: [0.01252685 0.98747313], Motion: 1.39\n",
      "Prediction: 1, Probabilities: [0.02820434 0.9717956 ], Motion: 1.43\n",
      "Prediction: 1, Probabilities: [0.02114197 0.97885805], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03105274 0.9689473 ], Motion: 1.57\n",
      "Prediction: 1, Probabilities: [0.02746933 0.97253066], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02745582 0.9725442 ], Motion: 1.89\n",
      "Prediction: 1, Probabilities: [0.02600151 0.9739985 ], Motion: 1.33\n",
      "Prediction: 1, Probabilities: [0.04766122 0.9523388 ], Motion: 0.86\n",
      "Prediction: 1, Probabilities: [0.04155158 0.9584484 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.07268798 0.927312  ], Motion: 1.65\n",
      "Prediction: 1, Probabilities: [0.09602983 0.9039702 ], Motion: 1.47\n",
      "Prediction: 1, Probabilities: [0.03759746 0.9624026 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06827889 0.93172115], Motion: 1.89\n",
      "Prediction: 1, Probabilities: [0.0810797 0.9189203], Motion: 1.82\n",
      "Prediction: 1, Probabilities: [0.1359864 0.8640136], Motion: 1.00\n",
      "Prediction: 1, Probabilities: [0.06505003 0.93495   ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04001907 0.9599809 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0263145  0.97368544], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04464824 0.9553518 ], Motion: 1.56\n",
      "Prediction: 1, Probabilities: [0.02250652 0.9774935 ], Motion: 1.22\n",
      "Prediction: 1, Probabilities: [0.02820099 0.971799  ], Motion: 0.92\n",
      "Prediction: 1, Probabilities: [0.04415167 0.95584834], Motion: 0.39\n",
      "Prediction: 1, Probabilities: [0.03273789 0.96726215], Motion: 0.61\n",
      "Prediction: 1, Probabilities: [0.02219452 0.9778055 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02477541 0.9752246 ], Motion: 0.35\n",
      "Prediction: 1, Probabilities: [0.0218161 0.9781839], Motion: 0.15\n",
      "Prediction: 1, Probabilities: [0.01901676 0.9809832 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01722101 0.98277897], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01644319 0.98355687], Motion: 0.28\n",
      "Prediction: 1, Probabilities: [0.0115329 0.9884671], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00997075 0.9900293 ], Motion: 0.18\n",
      "Prediction: 1, Probabilities: [0.00963604 0.990364  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01003595 0.98996407], Motion: 0.12\n",
      "Prediction: 1, Probabilities: [0.01653799 0.983462  ], Motion: 2.55\n",
      "Prediction: 1, Probabilities: [0.01272654 0.98727345], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01409686 0.98590314], Motion: 2.83\n",
      "Prediction: 1, Probabilities: [0.01459516 0.9854048 ], Motion: 3.83\n",
      "Prediction: 1, Probabilities: [0.02235097 0.97764903], Motion: 2.89\n",
      "Prediction: 1, Probabilities: [0.02827924 0.97172076], Motion: 4.72\n",
      "Prediction: 1, Probabilities: [0.02374106 0.9762589 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03869084 0.9613092 ], Motion: 2.85\n",
      "Prediction: 1, Probabilities: [0.03994933 0.9600507 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03929295 0.96070707], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01796216 0.9820379 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0191867 0.9808133], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01383743 0.9861626 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01083142 0.98916864], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00936382 0.99063617], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01665449 0.9833455 ], Motion: 2.71\n",
      "Prediction: 1, Probabilities: [0.01200141 0.9879986 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01002649 0.98997355], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00926593 0.9907341 ], Motion: 7.90\n",
      "Prediction: 1, Probabilities: [0.01204281 0.9879572 ], Motion: 0.35\n",
      "Prediction: 1, Probabilities: [0.00912754 0.99087244], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01113271 0.98886734], Motion: 0.93\n",
      "Prediction: 1, Probabilities: [0.01184789 0.9881521 ], Motion: 0.31\n",
      "Prediction: 1, Probabilities: [0.0106157  0.98938435], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01722608 0.9827739 ], Motion: 0.64\n",
      "Prediction: 1, Probabilities: [0.01534301 0.984657  ], Motion: 0.60\n",
      "Prediction: 1, Probabilities: [0.0198571 0.9801429], Motion: 0.65\n",
      "Prediction: 1, Probabilities: [0.01927305 0.98072696], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01935317 0.98064685], Motion: 7.08\n",
      "Prediction: 1, Probabilities: [0.0189685 0.9810315], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02517066 0.9748293 ], Motion: 6.02\n",
      "Prediction: 1, Probabilities: [0.02400813 0.97599185], Motion: 9.47\n",
      "Prediction: 1, Probabilities: [0.02022982 0.9797702 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02509967 0.97490036], Motion: 8.58\n",
      "Prediction: 1, Probabilities: [0.03003166 0.9699683 ], Motion: 3.19\n",
      "Prediction: 1, Probabilities: [0.03390624 0.96609384], Motion: 3.00\n",
      "Prediction: 1, Probabilities: [0.03595976 0.9640403 ], Motion: 1.08\n",
      "Prediction: 1, Probabilities: [0.03256616 0.9674338 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03531079 0.96468914], Motion: 0.62\n",
      "Prediction: 1, Probabilities: [0.04793805 0.9520619 ], Motion: 0.63\n",
      "Prediction: 1, Probabilities: [0.04665759 0.95334244], Motion: 0.65\n",
      "Prediction: 1, Probabilities: [0.05446752 0.94553244], Motion: 0.52\n",
      "Prediction: 1, Probabilities: [0.06191456 0.9380855 ], Motion: 0.40\n",
      "Prediction: 1, Probabilities: [0.05273597 0.94726396], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06075626 0.9392438 ], Motion: 0.75\n",
      "Prediction: 1, Probabilities: [0.03892542 0.9610746 ], Motion: 0.38\n",
      "Prediction: 1, Probabilities: [0.02957243 0.9704276 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04158371 0.95841634], Motion: 0.49\n",
      "Prediction: 1, Probabilities: [0.02494981 0.97505015], Motion: 0.15\n",
      "Prediction: 1, Probabilities: [0.01608482 0.9839152 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01286616 0.9871338 ], Motion: 0.22\n",
      "Prediction: 1, Probabilities: [0.01107078 0.9889292 ], Motion: 0.16\n",
      "Prediction: 1, Probabilities: [0.00951105 0.9904889 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0093358  0.99066424], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01074396 0.989256  ], Motion: 0.19\n",
      "Prediction: 1, Probabilities: [0.00884246 0.99115753], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.008744 0.991256], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00879095 0.99120903], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01071883 0.9892812 ], Motion: 1.93\n",
      "Prediction: 1, Probabilities: [0.01221141 0.9877886 ], Motion: 1.81\n",
      "Prediction: 1, Probabilities: [0.0121844  0.98781556], Motion: 1.65\n",
      "Prediction: 1, Probabilities: [0.01611715 0.98388284], Motion: 2.38\n",
      "Prediction: 1, Probabilities: [0.01304784 0.9869522 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01298997 0.98701   ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01333636 0.9866636 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01381086 0.9861892 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01441835 0.9855817 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02412683 0.97587323], Motion: 2.57\n",
      "Prediction: 1, Probabilities: [0.02367663 0.9763234 ], Motion: 1.95\n",
      "Prediction: 1, Probabilities: [0.013388   0.98661196], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01089982 0.98910016], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0098688  0.99013114], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01291275 0.98708725], Motion: 1.99\n",
      "Prediction: 1, Probabilities: [0.01541679 0.98458326], Motion: 0.45\n",
      "Prediction: 1, Probabilities: [0.01837462 0.9816253 ], Motion: 0.65\n",
      "Prediction: 1, Probabilities: [0.02467473 0.9753253 ], Motion: 1.21\n",
      "Prediction: 1, Probabilities: [0.02032004 0.97968   ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0172183 0.9827817], Motion: 0.25\n",
      "Prediction: 1, Probabilities: [0.01736167 0.98263836], Motion: 0.42\n",
      "Prediction: 1, Probabilities: [0.01820388 0.9817961 ], Motion: 0.25\n",
      "Prediction: 1, Probabilities: [0.01786664 0.9821333 ], Motion: 0.23\n",
      "Prediction: 1, Probabilities: [0.01858302 0.981417  ], Motion: 0.22\n",
      "Prediction: 1, Probabilities: [0.01854954 0.98145044], Motion: 2.23\n",
      "Prediction: 1, Probabilities: [0.02041454 0.9795855 ], Motion: 1.96\n",
      "Prediction: 1, Probabilities: [0.02407902 0.975921  ], Motion: 1.06\n",
      "Prediction: 1, Probabilities: [0.03037779 0.9696222 ], Motion: 2.51\n",
      "Prediction: 1, Probabilities: [0.0283131 0.9716869], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04426477 0.95573515], Motion: 2.88\n",
      "Prediction: 1, Probabilities: [0.05419664 0.94580334], Motion: 2.57\n",
      "Prediction: 1, Probabilities: [0.04688117 0.95311886], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.07737505 0.9226249 ], Motion: 2.44\n",
      "Prediction: 1, Probabilities: [0.1169749 0.8830251], Motion: 2.33\n",
      "Prediction: 1, Probabilities: [0.08947698 0.91052306], Motion: 2.14\n",
      "Prediction: 1, Probabilities: [0.08805805 0.911942  ], Motion: 3.05\n",
      "Prediction: 1, Probabilities: [0.0691762  0.93082374], Motion: 1.05\n",
      "Prediction: 1, Probabilities: [0.04795186 0.9520482 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.08866894 0.91133106], Motion: 1.41\n",
      "Prediction: 1, Probabilities: [0.05067822 0.9493218 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.05889147 0.9411086 ], Motion: 0.92\n",
      "Prediction: 1, Probabilities: [0.07092491 0.9290751 ], Motion: 0.37\n",
      "Prediction: 1, Probabilities: [0.06773494 0.9322651 ], Motion: 2.25\n",
      "Prediction: 1, Probabilities: [0.04399368 0.9560063 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04271085 0.95728916], Motion: 3.83\n",
      "Prediction: 1, Probabilities: [0.03285518 0.96714485], Motion: 8.14\n",
      "Prediction: 1, Probabilities: [0.0386165  0.96138346], Motion: 6.64\n",
      "Prediction: 1, Probabilities: [0.05350434 0.9464956 ], Motion: 4.86\n",
      "Prediction: 1, Probabilities: [0.06257211 0.9374279 ], Motion: 2.50\n",
      "Prediction: 1, Probabilities: [0.09133698 0.90866303], Motion: 1.72\n",
      "Prediction: 1, Probabilities: [0.10703766 0.89296234], Motion: 2.54\n",
      "Prediction: 1, Probabilities: [0.12182645 0.87817353], Motion: 1.96\n",
      "Prediction: 1, Probabilities: [0.06967713 0.9303229 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.07319671 0.9268033 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06736901 0.93263096], Motion: 1.57\n",
      "Prediction: 1, Probabilities: [0.04423361 0.95576644], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.05554346 0.9444565 ], Motion: 0.80\n",
      "Prediction: 1, Probabilities: [0.03295729 0.9670427 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02725523 0.9727447 ], Motion: 0.41\n",
      "Prediction: 1, Probabilities: [0.01965255 0.9803475 ], Motion: 0.36\n",
      "Prediction: 1, Probabilities: [0.01633101 0.983669  ], Motion: 0.34\n",
      "Prediction: 1, Probabilities: [0.01383738 0.9861626 ], Motion: 0.12\n",
      "Prediction: 1, Probabilities: [0.01260114 0.98739886], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01521591 0.9847841 ], Motion: 0.18\n",
      "Prediction: 1, Probabilities: [0.01097167 0.98902833], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01276592 0.9872341 ], Motion: 0.24\n",
      "Prediction: 1, Probabilities: [0.01036472 0.9896353 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01512511 0.9848749 ], Motion: 1.19\n",
      "Prediction: 1, Probabilities: [0.01514123 0.9848587 ], Motion: 3.61\n",
      "Prediction: 1, Probabilities: [0.02078252 0.9792175 ], Motion: 1.01\n",
      "Prediction: 1, Probabilities: [0.01604739 0.9839526 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02424938 0.9757506 ], Motion: 1.75\n",
      "Prediction: 1, Probabilities: [0.03349412 0.9665059 ], Motion: 2.11\n",
      "Prediction: 1, Probabilities: [0.02785806 0.9721419 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.05118113 0.94881886], Motion: 1.90\n",
      "Prediction: 1, Probabilities: [0.07224001 0.92775995], Motion: 1.41\n",
      "Prediction: 1, Probabilities: [0.06866784 0.9313321 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.07024024 0.9297598 ], Motion: 1.34\n",
      "Prediction: 1, Probabilities: [0.03575107 0.96424896], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0201331  0.97986686], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02044952 0.9795505 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02484427 0.97515565], Motion: 2.37\n",
      "Prediction: 1, Probabilities: [0.02863071 0.97136927], Motion: 2.57\n",
      "Prediction: 1, Probabilities: [0.04372433 0.9562757 ], Motion: 3.15\n",
      "Prediction: 1, Probabilities: [0.02247097 0.97752905], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01536571 0.98463434], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02397836 0.9760216 ], Motion: 2.08\n",
      "Prediction: 1, Probabilities: [0.01916954 0.98083043], Motion: 0.32\n",
      "Prediction: 1, Probabilities: [0.01852299 0.98147696], Motion: 0.12\n",
      "Prediction: 1, Probabilities: [0.01726873 0.9827313 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02747416 0.97252584], Motion: 0.29\n",
      "Prediction: 1, Probabilities: [0.01548972 0.98451024], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01377369 0.98622626], Motion: 0.27\n",
      "Prediction: 1, Probabilities: [0.0106221 0.9893779], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01178006 0.98822   ], Motion: 0.16\n",
      "Prediction: 1, Probabilities: [0.01306593 0.98693407], Motion: 0.27\n",
      "Prediction: 1, Probabilities: [0.01072063 0.9892793 ], Motion: 0.20\n",
      "Prediction: 1, Probabilities: [0.01091202 0.98908794], Motion: 0.07\n",
      "Prediction: 1, Probabilities: [0.01008482 0.98991525], Motion: 0.13\n",
      "Prediction: 1, Probabilities: [0.01067837 0.9893216 ], Motion: 0.18\n",
      "Prediction: 1, Probabilities: [0.00788165 0.99211836], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01128569 0.9887143 ], Motion: 0.37\n",
      "Prediction: 1, Probabilities: [0.01561467 0.9843853 ], Motion: 1.17\n",
      "Prediction: 1, Probabilities: [0.0113604 0.9886396], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0134024 0.9865976], Motion: 2.82\n",
      "Prediction: 1, Probabilities: [0.01208498 0.98791504], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01122289 0.9887771 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01488571 0.98511434], Motion: 4.55\n",
      "Prediction: 1, Probabilities: [0.02368413 0.9763158 ], Motion: 1.82\n",
      "Prediction: 1, Probabilities: [0.01757306 0.982427  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.03121517 0.9687848 ], Motion: 2.34\n",
      "Prediction: 1, Probabilities: [0.02086541 0.97913456], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01998713 0.98001283], Motion: 2.76\n",
      "Prediction: 1, Probabilities: [0.03400704 0.965993  ], Motion: 2.00\n",
      "Prediction: 1, Probabilities: [0.04188073 0.9581193 ], Motion: 2.05\n",
      "Prediction: 1, Probabilities: [0.06179513 0.9382049 ], Motion: 0.92\n",
      "Prediction: 1, Probabilities: [0.06135669 0.9386433 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.06231033 0.9376896 ], Motion: 1.04\n",
      "Prediction: 1, Probabilities: [0.05243511 0.9475649 ], Motion: 3.80\n",
      "Prediction: 1, Probabilities: [0.10503116 0.8949688 ], Motion: 2.50\n",
      "Prediction: 1, Probabilities: [0.09797731 0.90202266], Motion: 1.86\n",
      "Prediction: 1, Probabilities: [0.16371131 0.8362887 ], Motion: 1.30\n",
      "Prediction: 1, Probabilities: [0.15351865 0.8464813 ], Motion: 1.08\n",
      "Prediction: 1, Probabilities: [0.13825203 0.861748  ], Motion: 0.75\n",
      "Prediction: 1, Probabilities: [0.07667886 0.9233211 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.04929541 0.95070463], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.09666672 0.90333325], Motion: 0.82\n",
      "Prediction: 1, Probabilities: [0.06414679 0.9358532 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.07430684 0.92569315], Motion: 0.57\n",
      "Prediction: 1, Probabilities: [0.0447198  0.95528024], Motion: 0.20\n",
      "Prediction: 1, Probabilities: [0.0233863 0.9766137], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02004395 0.97995603], Motion: 0.27\n",
      "Prediction: 1, Probabilities: [0.02035021 0.9796498 ], Motion: 0.47\n",
      "Prediction: 1, Probabilities: [0.0155645 0.9844355], Motion: 1.31\n",
      "Prediction: 1, Probabilities: [0.01257821 0.98742175], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01779819 0.9822019 ], Motion: 7.10\n",
      "Prediction: 1, Probabilities: [0.01431309 0.98568696], Motion: 6.39\n",
      "Prediction: 1, Probabilities: [0.01859082 0.9814092 ], Motion: 5.53\n",
      "Prediction: 1, Probabilities: [0.01406217 0.9859378 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01609305 0.983907  ], Motion: 7.89\n",
      "Prediction: 1, Probabilities: [0.0259218  0.97407824], Motion: 8.87\n",
      "Prediction: 1, Probabilities: [0.02183104 0.97816896], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0202509  0.97974914], Motion: 4.97\n",
      "Prediction: 1, Probabilities: [0.01533618 0.9846638 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02656019 0.9734398 ], Motion: 2.46\n",
      "Prediction: 1, Probabilities: [0.01756777 0.98243225], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02191376 0.9780862 ], Motion: 2.35\n",
      "Prediction: 1, Probabilities: [0.01942061 0.98057944], Motion: 2.94\n",
      "Prediction: 1, Probabilities: [0.02014012 0.9798599 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0193857 0.9806143], Motion: 2.96\n",
      "Prediction: 1, Probabilities: [0.0152987 0.9847013], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01987336 0.9801267 ], Motion: 4.96\n",
      "Prediction: 1, Probabilities: [0.01663632 0.9833636 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01633495 0.98366505], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01393121 0.9860687 ], Motion: 13.55\n",
      "Prediction: 1, Probabilities: [0.02175268 0.97824734], Motion: 22.96\n",
      "Prediction: 1, Probabilities: [0.01827102 0.981729  ], Motion: 12.12\n",
      "Prediction: 1, Probabilities: [0.01219762 0.9878023 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01719847 0.9828015 ], Motion: 8.68\n",
      "Prediction: 1, Probabilities: [0.01079177 0.98920816], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01492143 0.9850786 ], Motion: 5.84\n",
      "Prediction: 1, Probabilities: [0.01124137 0.98875856], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01492368 0.98507625], Motion: 1.55\n",
      "Prediction: 1, Probabilities: [0.01525918 0.9847408 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.02368447 0.9763155 ], Motion: 0.65\n",
      "Prediction: 1, Probabilities: [0.02252743 0.97747254], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0158664 0.9841336], Motion: 0.16\n",
      "Prediction: 1, Probabilities: [0.0147775 0.9852225], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01166088 0.98833907], Motion: 0.46\n",
      "Prediction: 1, Probabilities: [0.01332656 0.9866735 ], Motion: 0.15\n",
      "Prediction: 1, Probabilities: [0.01111796 0.988882  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01322565 0.9867743 ], Motion: 0.30\n",
      "Prediction: 1, Probabilities: [0.01083143 0.9891685 ], Motion: 0.37\n",
      "Prediction: 1, Probabilities: [0.0105705  0.98942953], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0101098 0.9898902], Motion: 0.16\n",
      "Prediction: 1, Probabilities: [0.02121313 0.9787869 ], Motion: 0.60\n",
      "Prediction: 1, Probabilities: [0.01744042 0.98255956], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01497536 0.9850247 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01512568 0.9848743 ], Motion: 0.28\n",
      "Prediction: 1, Probabilities: [0.01201107 0.98798895], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01326049 0.9867395 ], Motion: 17.67\n",
      "Prediction: 1, Probabilities: [0.0100905 0.9899095], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01339339 0.9866066 ], Motion: 15.07\n",
      "Prediction: 1, Probabilities: [0.01033372 0.9896662 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00933527 0.9906647 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00993903 0.9900609 ], Motion: 9.25\n",
      "Prediction: 1, Probabilities: [0.00843144 0.9915686 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00815072 0.9918493 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00788727 0.99211276], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00821238 0.9917876 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00916449 0.99083555], Motion: 5.98\n",
      "Prediction: 1, Probabilities: [0.00826242 0.99173754], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00829971 0.99170023], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00899998 0.991     ], Motion: 3.25\n",
      "Prediction: 1, Probabilities: [0.00885342 0.9911466 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00838093 0.9916191 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00827439 0.99172556], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00951266 0.9904874 ], Motion: 1.26\n",
      "Prediction: 1, Probabilities: [0.00792359 0.9920764 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00789817 0.99210185], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00810727 0.9918927 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00821635 0.9917836 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01161506 0.98838496], Motion: 0.35\n",
      "Prediction: 1, Probabilities: [0.00817116 0.99182886], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00801019 0.9919898 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0098734 0.9901266], Motion: 2.19\n",
      "Prediction: 1, Probabilities: [0.00932801 0.990672  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00922279 0.99077713], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00909633 0.9909037 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00902415 0.9909759 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01130402 0.988696  ], Motion: 4.20\n",
      "Prediction: 1, Probabilities: [0.00900762 0.9909924 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00878625 0.99121374], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00886711 0.9911329 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0084684  0.99153155], Motion: 2.78\n",
      "Prediction: 1, Probabilities: [0.00796646 0.99203354], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00938023 0.9906198 ], Motion: 2.86\n",
      "Prediction: 1, Probabilities: [0.00712418 0.9928758 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00705411 0.99294585], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0071663  0.99283373], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00745824 0.9925418 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00760153 0.99239844], Motion: 1.82\n",
      "Prediction: 1, Probabilities: [0.0078772 0.9921228], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00793788 0.9920621 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0077701 0.9922299], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00697112 0.99302894], Motion: 2.12\n",
      "Prediction: 1, Probabilities: [0.008414   0.99158597], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00857425 0.99142575], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0086572 0.9913428], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00875534 0.9912446 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00881946 0.9911806 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01297041 0.9870297 ], Motion: 1.32\n",
      "Prediction: 1, Probabilities: [0.01016478 0.9898352 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01460757 0.9853924 ], Motion: 1.08\n",
      "Prediction: 1, Probabilities: [0.01001494 0.9899851 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00968484 0.99031514], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00942468 0.9905753 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01106508 0.98893493], Motion: 0.80\n",
      "Prediction: 1, Probabilities: [0.00964496 0.990355  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00961108 0.99038893], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0099376 0.9900624], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01024383 0.98975617], Motion: 0.56\n",
      "Prediction: 1, Probabilities: [0.00833633 0.9916637 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00794198 0.992058  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00805663 0.99194336], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.008181 0.991819], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01116294 0.988837  ], Motion: 0.24\n",
      "Prediction: 1, Probabilities: [0.00818269 0.9918173 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00812949 0.9918705 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00998342 0.99001664], Motion: 0.33\n",
      "Prediction: 1, Probabilities: [0.00834204 0.9916579 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00843878 0.99156123], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00849884 0.9915011 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01095358 0.9890464 ], Motion: 1.65\n",
      "Prediction: 1, Probabilities: [0.00991224 0.9900878 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00940027 0.9905997 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01063156 0.9893685 ], Motion: 1.57\n",
      "Prediction: 1, Probabilities: [0.00875261 0.99124736], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0086806  0.99131936], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00852041 0.9914795 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00845502 0.99154496], Motion: 1.70\n",
      "Prediction: 1, Probabilities: [0.00861191 0.99138814], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00889365 0.99110633], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00829263 0.9917074 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00934066 0.99065936], Motion: 1.18\n",
      "Prediction: 1, Probabilities: [0.0082857 0.9917143], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00815282 0.99184716], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00828772 0.99171233], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00842573 0.9915742 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00817538 0.9918247 ], Motion: 1.81\n",
      "Prediction: 1, Probabilities: [0.00845139 0.9915486 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0084481 0.9915519], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00844108 0.9915589 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01123729 0.9887627 ], Motion: 1.02\n",
      "Prediction: 1, Probabilities: [0.00937941 0.9906206 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00900579 0.99099416], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01180752 0.9881925 ], Motion: 2.14\n",
      "Prediction: 1, Probabilities: [0.01043464 0.9895654 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00997309 0.99002695], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0092407  0.99075925], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00915991 0.99084014], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01016111 0.98983884], Motion: 7.37\n",
      "Prediction: 1, Probabilities: [0.0090207 0.9909793], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00816045 0.9918395 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00817802 0.99182194], Motion: 6.42\n",
      "Prediction: 1, Probabilities: [0.00741926 0.9925808 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00674054 0.9932595 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00687615 0.9931238 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00811132 0.9918887 ], Motion: 0.68\n",
      "Prediction: 1, Probabilities: [0.00687851 0.99312145], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00715758 0.99284244], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00734563 0.9926543 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0074742 0.9925258], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00912229 0.9908777 ], Motion: 0.84\n",
      "Prediction: 1, Probabilities: [0.00806221 0.9919378 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01114222 0.98885775], Motion: 1.26\n",
      "Prediction: 1, Probabilities: [0.0083753 0.9916248], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00827898 0.99172103], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00842956 0.9915705 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00854561 0.99145436], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00971124 0.99028873], Motion: 5.13\n",
      "Prediction: 1, Probabilities: [0.01021244 0.9897876 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00997113 0.9900289 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00915087 0.99084914], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0106506  0.98934937], Motion: 3.32\n",
      "Prediction: 1, Probabilities: [0.00954258 0.9904574 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00934228 0.9906577 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00923077 0.9907692 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01056888 0.98943114], Motion: 3.79\n",
      "Prediction: 1, Probabilities: [0.00980941 0.9901905 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00907969 0.9909203 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0090216  0.99097836], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01511978 0.9848802 ], Motion: 1.41\n",
      "Prediction: 1, Probabilities: [0.01158629 0.98841375], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00992257 0.9900774 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01263776 0.98736227], Motion: 0.97\n",
      "Prediction: 1, Probabilities: [0.01037072 0.9896292 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01001506 0.989985  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00942934 0.99057066], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01355068 0.9864493 ], Motion: 0.37\n",
      "Prediction: 1, Probabilities: [0.01010784 0.98989224], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0101807  0.98981935], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0087838 0.9912162], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01378597 0.986214  ], Motion: 0.29\n",
      "Prediction: 1, Probabilities: [0.0095212 0.9904789], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00877754 0.9912225 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00868338 0.99131656], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00832295 0.99167705], Motion: 0.44\n",
      "Prediction: 1, Probabilities: [0.00856921 0.9914308 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00852018 0.99147975], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00853937 0.9914607 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01292805 0.98707193], Motion: 0.34\n",
      "Prediction: 1, Probabilities: [0.00905005 0.9909499 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00850676 0.9914932 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00839046 0.9916095 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01047105 0.98952895], Motion: 0.39\n",
      "Prediction: 1, Probabilities: [0.00835566 0.9916443 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00844122 0.9915588 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00842506 0.99157494], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00964768 0.99035233], Motion: 1.14\n",
      "Prediction: 1, Probabilities: [0.00891568 0.99108434], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00884144 0.99115855], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00879976 0.99120027], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01079168 0.9892083 ], Motion: 1.59\n",
      "Prediction: 1, Probabilities: [0.0104224  0.98957765], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01004252 0.9899575 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01144158 0.9885584 ], Motion: 1.09\n",
      "Prediction: 1, Probabilities: [0.01119796 0.9888021 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01127585 0.9887242 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00974511 0.99025494], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00982522 0.9901748 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01544854 0.9845515 ], Motion: 1.77\n",
      "Prediction: 1, Probabilities: [0.01306066 0.9869393 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01029731 0.98970264], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01469766 0.9853023 ], Motion: 1.36\n",
      "Prediction: 1, Probabilities: [0.0115212  0.98847884], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00971193 0.990288  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00944767 0.9905523 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00943916 0.9905608 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00965987 0.9903402 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01645864 0.9835414 ], Motion: 0.75\n",
      "Prediction: 1, Probabilities: [0.01000477 0.98999524], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0094618 0.9905381], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01227021 0.9877297 ], Motion: 0.42\n",
      "Prediction: 1, Probabilities: [0.00905102 0.990949  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00883069 0.99116933], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00876099 0.991239  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01195798 0.988042  ], Motion: 0.30\n",
      "Prediction: 1, Probabilities: [0.00952402 0.990476  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00949606 0.99050397], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0089421 0.9910579], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00887755 0.9911225 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00814601 0.99185395], Motion: 7.31\n",
      "Prediction: 1, Probabilities: [0.00816867 0.99183136], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00961365 0.99038637], Motion: 8.49\n",
      "Prediction: 1, Probabilities: [0.00869838 0.9913016 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00869127 0.9913087 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00830114 0.99169886], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00832972 0.99167025], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01311676 0.9868832 ], Motion: 16.15\n",
      "Prediction: 1, Probabilities: [0.0092463  0.99075377], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00906164 0.9909383 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0088783  0.99112165], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01072858 0.9892714 ], Motion: 9.63\n",
      "Prediction: 1, Probabilities: [0.00899065 0.99100935], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0086667 0.9913333], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00849431 0.9915057 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00965216 0.99034786], Motion: 5.94\n",
      "Prediction: 1, Probabilities: [0.00873964 0.99126035], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00853527 0.9914648 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00846938 0.99153066], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00851824 0.9914818 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00878324 0.9912168 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00844694 0.991553  ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00845832 0.9915417 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01063654 0.9893635 ], Motion: 2.98\n",
      "Prediction: 1, Probabilities: [0.00945814 0.9905419 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00901578 0.9909842 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00882334 0.9911767 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.0087069  0.99129313], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00864215 0.9913578 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00861682 0.99138325], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00864374 0.99135625], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01245823 0.98754174], Motion: 1.44\n",
      "Prediction: 1, Probabilities: [0.01031555 0.98968446], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00900762 0.9909924 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00885102 0.99114895], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00878836 0.9912116 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00876636 0.99123365], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00877372 0.99122626], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.01276723 0.9872328 ], Motion: 14.06\n",
      "Prediction: 1, Probabilities: [0.00889295 0.99110705], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00876106 0.9912389 ], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00779505 0.99220496], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00779379 0.99220616], Motion: 0.00\n",
      "Prediction: 1, Probabilities: [0.00781516 0.9921848 ], Motion: 0.00\n"
     ]
    }
   ],
   "source": [
    "#Testing of Model 3\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import pygame\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- Model Definition ---\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "# --- Setup ---\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "AUDIO_FILE = \"beep.wav\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(\"tapping_feet_mobilenet3.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Init MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_tracker = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Frame transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- GUI App ---\n",
    "class TapCounterApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"BEA - Foot Tapping Counter (Per Minute Display)\")\n",
    "\n",
    "        self.canvas = tk.Label(root)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.count_label = tk.Label(root, text=\"Taps this minute: 0\", font=(\"Arial\", 18))\n",
    "        self.count_label.pack(pady=5)\n",
    "\n",
    "        self.total_label = tk.Label(root, text=\"Total Minutes Logged: 0\", font=(\"Arial\", 14))\n",
    "        self.total_label.pack(pady=5)\n",
    "\n",
    "        self.advisory_label = tk.Label(root, text=\"ADHD Likelihood: Not enough data\", font=(\"Arial\", 14), fg=\"blue\")\n",
    "        self.advisory_label.pack(pady=5)\n",
    "\n",
    "        self.cap = cv2.VideoCapture(1)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "        self.frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "        self.tap_count = 0\n",
    "        self.total_minutes = 0\n",
    "        self.last_tap_time = time.time()\n",
    "        self.min_interval = 0.3\n",
    "        self.prev_pred = 0\n",
    "        self.prev_gray = None\n",
    "\n",
    "        self.start_time = time.time()\n",
    "        self.last_logged_minute = 0\n",
    "\n",
    "        self.update_frame()\n",
    "\n",
    "    def update_frame(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(10, self.update_frame)\n",
    "            return\n",
    "\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        display_img = cv2.resize(rgb, (640, 480))\n",
    "        model_input_frame = display_img.copy()\n",
    "\n",
    "        pose_results = pose_tracker.process(display_img)\n",
    "        pose_valid = False\n",
    "\n",
    "        if pose_results.pose_landmarks:\n",
    "            h, w, _ = display_img.shape\n",
    "            lm = pose_results.pose_landmarks.landmark\n",
    "\n",
    "            required_landmarks = [\n",
    "                mp_pose.PoseLandmark.LEFT_KNEE,\n",
    "                mp_pose.PoseLandmark.LEFT_ANKLE,\n",
    "                mp_pose.PoseLandmark.RIGHT_KNEE,\n",
    "                mp_pose.PoseLandmark.RIGHT_ANKLE\n",
    "            ]\n",
    "\n",
    "            pose_valid = all(lm[i].visibility > 0.5 for i in required_landmarks)\n",
    "\n",
    "            def get_coord(index):\n",
    "                point = lm[index]\n",
    "                return int(point.x * w), int(point.y * h)\n",
    "\n",
    "            LEG_PAIRS = [\n",
    "                (mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.LEFT_HEEL),\n",
    "                (mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.LEFT_FOOT_INDEX),\n",
    "                (mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE),\n",
    "                (mp_pose.PoseLandmark.RIGHT_ANKLE, mp_pose.PoseLandmark.RIGHT_HEEL),\n",
    "                (mp_pose.PoseLandmark.RIGHT_HEEL, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX)\n",
    "            ]\n",
    "\n",
    "            for start, end in LEG_PAIRS:\n",
    "                x1, y1 = get_coord(start)\n",
    "                x2, y2 = get_coord(end)\n",
    "                cv2.line(display_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                cv2.circle(display_img, (x1, y1), 6, (0, 255, 0), -1)\n",
    "                cv2.circle(display_img, (x2, y2), 6, (0, 255, 0), -1)\n",
    "\n",
    "        img = Image.fromarray(display_img)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.canvas.imgtk = imgtk\n",
    "        self.canvas.configure(image=imgtk)\n",
    "\n",
    "        if pose_valid:\n",
    "            gray = cv2.cvtColor(model_input_frame, cv2.COLOR_RGB2GRAY)\n",
    "            if self.prev_gray is None:\n",
    "                self.prev_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "                self.root.after(30, self.update_frame)\n",
    "                return\n",
    "\n",
    "            curr_gray = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "            diff = cv2.absdiff(self.prev_gray, curr_gray)\n",
    "            self.prev_gray = curr_gray\n",
    "            motion = np.mean(diff)\n",
    "\n",
    "            diff = np.expand_dims(diff, axis=-1)\n",
    "            diff = np.repeat(diff, 3, axis=-1)\n",
    "            diff = transform(diff)\n",
    "            self.frame_queue.append(diff)\n",
    "\n",
    "            if len(self.frame_queue) == SEQ_FRAMES:\n",
    "                sequence = torch.stack(list(self.frame_queue)).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(sequence)\n",
    "                    probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                    pred = np.argmax(probs)\n",
    "\n",
    "                tap_conf = probs[1]\n",
    "                current_time = time.time()\n",
    "                print(f\"Prediction: {pred}, Probabilities: {probs}, Motion: {motion:.2f}\")\n",
    "\n",
    "                if pred == 1 and tap_conf > 0.8 and motion > 2.0 and (current_time - self.last_tap_time > self.min_interval):\n",
    "                    self.tap_count += 1\n",
    "                    self.last_tap_time = current_time\n",
    "                    self.count_label.config(text=f\"Taps this minute: {self.tap_count}\")\n",
    "\n",
    "        elapsed_minutes = int((time.time() - self.start_time) // 60)\n",
    "        if elapsed_minutes > self.last_logged_minute:\n",
    "            self.last_logged_minute = elapsed_minutes\n",
    "            self.total_minutes += 1\n",
    "\n",
    "            if self.tap_count <= 1:\n",
    "                advisory = \"Least likely to have ADHD.\"\n",
    "            elif 2 <= self.tap_count <= 4:\n",
    "                advisory = \"Moderately likely to have ADHD.\"\n",
    "            else:\n",
    "                advisory = \"Most likely to have ADHD.\"\n",
    "\n",
    "            self.count_label.config(text=f\"Taps this minute: 0\")\n",
    "            self.total_label.config(text=f\"Total Minutes Logged: {self.total_minutes}\")\n",
    "            self.advisory_label.config(text=f\"ADHD Likelihood: {advisory}\")\n",
    "            self.tap_count = 0\n",
    "\n",
    "        self.root.after(30, self.update_frame)\n",
    "\n",
    "    def on_close(self):\n",
    "        self.cap.release()\n",
    "        self.root.destroy()\n",
    "\n",
    "# --- Run GUI ---\n",
    "root = tk.Tk()\n",
    "app = TapCounterApp(root)\n",
    "root.protocol(\"WM_DELETE_WINDOW\", app.on_close)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff42df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Taps Detected: 5\n"
     ]
    }
   ],
   "source": [
    "##VIDEO TESTING\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, models\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        self.feature_extractor = mobilenet.features\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.lstm = nn.LSTM(input_size=1280, hidden_size=hidden_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, c, h, w = x.size()\n",
    "        x = x.view(-1, c, h, w)\n",
    "        with torch.no_grad():\n",
    "            x = self.feature_extractor(x)\n",
    "            x = self.pool(x)\n",
    "        x = x.view(b, t, -1)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.classifier(lstm_out[:, -1])\n",
    "        return out\n",
    "\n",
    "SEQ_FRAMES = 10\n",
    "IMG_SIZE = 64\n",
    "VIDEO_PATH = \"test_tapping.mp4\"\n",
    "MODEL_PATH = \"tapping_feet_mobilenet2.pth\"\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = CNNLSTM().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "frame_queue = deque(maxlen=SEQ_FRAMES)\n",
    "tap_count = 0\n",
    "last_tap_time = 0\n",
    "min_interval = 0.5\n",
    "prev_frame = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = cv2.resize(rgb, (IMG_SIZE, IMG_SIZE))\n",
    "    tensor = transform(resized)\n",
    "    frame_queue.append(tensor)\n",
    "\n",
    "    if len(frame_queue) == SEQ_FRAMES:\n",
    "        sequence = torch.stack(list(frame_queue)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(sequence)\n",
    "            probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "            pred = np.argmax(probs)\n",
    "\n",
    "        motion = np.mean(cv2.absdiff(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY), cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))) if prev_frame is not None else 0\n",
    "        prev_frame = frame.copy()\n",
    "\n",
    "        current_time = time.time()\n",
    "        if pred == 1 and probs[1] > 0.7 and (current_time - last_tap_time > min_interval):\n",
    "            tap_count += 1\n",
    "            last_tap_time = current_time\n",
    "\n",
    "        label = f\"Pred: {pred}, Prob: {probs[1]:.2f}, Motion: {motion:.1f}, Taps: {tap_count}\"\n",
    "        cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Tap Test\", frame)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Total Taps Detected:\", tap_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
